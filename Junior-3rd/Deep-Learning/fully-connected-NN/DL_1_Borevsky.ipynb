{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q_upCOEI3Upu"
   },
   "source": [
    "# Введение в глубинное обучение, ФКН ВШЭ\n",
    "\n",
    "## Домашнее задание 1. Введение в PyTorch. Полносвязные нейронные сети.\n",
    "\n",
    "### Общая информация\n",
    "\n",
    "Дата выдачи: 05.10.2021\n",
    "\n",
    "Мягкий дедлайн: 23:59MSK 19.10.2021\n",
    "\n",
    "Жесткий дедлайн: 23:59MSK 23.10.2021\n",
    "\n",
    "Оценка после штрафа после мягкого дедлайна вычисляется по формуле $M_{penalty} = M_{full} \\cdot 0.85^{t/1440}$, где $M_{full}$ &mdash; полная оценка за работу без учета штрафа, а $t$ &mdash; время в минутах, прошедшее после мягкого дедлайна (округление до двух цифр после запятой). Таким образом, спустя первые сутки после мягкого дедлайна вы не можете получить оценку выше **8.5**, а если сдать перед самым жестким дедлайном, то ваш максимум &mdash; **5.22** балла.\n",
    "\n",
    "### Оценивание и штрафы\n",
    "Максимально допустимая оценка за работу — 10 баллов. Сдавать задание после указанного срока сдачи нельзя.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов. Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке.\n",
    "Также оценка может быть снижена за плохо читаемый код и плохо оформленные графики. Все ответы должны сопровождаться кодом или комментариями о том, как они были получены.\n",
    "\n",
    "### О задании\n",
    "\n",
    "В этом задании вам предстоит предсказывать год выпуска песни по некоторым звуковым признакам: [данные](https://archive.ics.uci.edu/ml/datasets/yearpredictionmsd). В ячейках ниже находится код для загрузки данных. Обратите внимание, что обучающая и тестовая выборки располагаются в одном файле, поэтому НЕ меняйте ячейку, в которой производится деление данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "RI_eoe063VaP"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, clear_output\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "DSVJZzkJ7zZE"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001</td>\n",
       "      <td>49.94357</td>\n",
       "      <td>21.47114</td>\n",
       "      <td>73.07750</td>\n",
       "      <td>8.74861</td>\n",
       "      <td>-17.40628</td>\n",
       "      <td>-13.09905</td>\n",
       "      <td>-25.01202</td>\n",
       "      <td>-12.23257</td>\n",
       "      <td>7.83089</td>\n",
       "      <td>...</td>\n",
       "      <td>13.01620</td>\n",
       "      <td>-54.40548</td>\n",
       "      <td>58.99367</td>\n",
       "      <td>15.37344</td>\n",
       "      <td>1.11144</td>\n",
       "      <td>-23.08793</td>\n",
       "      <td>68.40795</td>\n",
       "      <td>-1.82223</td>\n",
       "      <td>-27.46348</td>\n",
       "      <td>2.26327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>48.73215</td>\n",
       "      <td>18.42930</td>\n",
       "      <td>70.32679</td>\n",
       "      <td>12.94636</td>\n",
       "      <td>-10.32437</td>\n",
       "      <td>-24.83777</td>\n",
       "      <td>8.76630</td>\n",
       "      <td>-0.92019</td>\n",
       "      <td>18.76548</td>\n",
       "      <td>...</td>\n",
       "      <td>5.66812</td>\n",
       "      <td>-19.68073</td>\n",
       "      <td>33.04964</td>\n",
       "      <td>42.87836</td>\n",
       "      <td>-9.90378</td>\n",
       "      <td>-32.22788</td>\n",
       "      <td>70.49388</td>\n",
       "      <td>12.04941</td>\n",
       "      <td>58.43453</td>\n",
       "      <td>26.92061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001</td>\n",
       "      <td>50.95714</td>\n",
       "      <td>31.85602</td>\n",
       "      <td>55.81851</td>\n",
       "      <td>13.41693</td>\n",
       "      <td>-6.57898</td>\n",
       "      <td>-18.54940</td>\n",
       "      <td>-3.27872</td>\n",
       "      <td>-2.35035</td>\n",
       "      <td>16.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>3.03800</td>\n",
       "      <td>26.05866</td>\n",
       "      <td>-50.92779</td>\n",
       "      <td>10.93792</td>\n",
       "      <td>-0.07568</td>\n",
       "      <td>43.20130</td>\n",
       "      <td>-115.00698</td>\n",
       "      <td>-0.05859</td>\n",
       "      <td>39.67068</td>\n",
       "      <td>-0.66345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001</td>\n",
       "      <td>48.24750</td>\n",
       "      <td>-1.89837</td>\n",
       "      <td>36.29772</td>\n",
       "      <td>2.58776</td>\n",
       "      <td>0.97170</td>\n",
       "      <td>-26.21683</td>\n",
       "      <td>5.05097</td>\n",
       "      <td>-10.34124</td>\n",
       "      <td>3.55005</td>\n",
       "      <td>...</td>\n",
       "      <td>34.57337</td>\n",
       "      <td>-171.70734</td>\n",
       "      <td>-16.96705</td>\n",
       "      <td>-46.67617</td>\n",
       "      <td>-12.51516</td>\n",
       "      <td>82.58061</td>\n",
       "      <td>-72.08993</td>\n",
       "      <td>9.90558</td>\n",
       "      <td>199.62971</td>\n",
       "      <td>18.85382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001</td>\n",
       "      <td>50.97020</td>\n",
       "      <td>42.20998</td>\n",
       "      <td>67.09964</td>\n",
       "      <td>8.46791</td>\n",
       "      <td>-15.85279</td>\n",
       "      <td>-16.81409</td>\n",
       "      <td>-12.48207</td>\n",
       "      <td>-9.37636</td>\n",
       "      <td>12.63699</td>\n",
       "      <td>...</td>\n",
       "      <td>9.92661</td>\n",
       "      <td>-55.95724</td>\n",
       "      <td>64.92712</td>\n",
       "      <td>-17.72522</td>\n",
       "      <td>-1.49237</td>\n",
       "      <td>-7.50035</td>\n",
       "      <td>51.76631</td>\n",
       "      <td>7.88713</td>\n",
       "      <td>55.66926</td>\n",
       "      <td>28.74903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1         2         3         4         5         6         7   \\\n",
       "0  2001  49.94357  21.47114  73.07750   8.74861 -17.40628 -13.09905 -25.01202   \n",
       "1  2001  48.73215  18.42930  70.32679  12.94636 -10.32437 -24.83777   8.76630   \n",
       "2  2001  50.95714  31.85602  55.81851  13.41693  -6.57898 -18.54940  -3.27872   \n",
       "3  2001  48.24750  -1.89837  36.29772   2.58776   0.97170 -26.21683   5.05097   \n",
       "4  2001  50.97020  42.20998  67.09964   8.46791 -15.85279 -16.81409 -12.48207   \n",
       "\n",
       "         8         9   ...        81         82        83        84        85  \\\n",
       "0 -12.23257   7.83089  ...  13.01620  -54.40548  58.99367  15.37344   1.11144   \n",
       "1  -0.92019  18.76548  ...   5.66812  -19.68073  33.04964  42.87836  -9.90378   \n",
       "2  -2.35035  16.07017  ...   3.03800   26.05866 -50.92779  10.93792  -0.07568   \n",
       "3 -10.34124   3.55005  ...  34.57337 -171.70734 -16.96705 -46.67617 -12.51516   \n",
       "4  -9.37636  12.63699  ...   9.92661  -55.95724  64.92712 -17.72522  -1.49237   \n",
       "\n",
       "         86         87        88         89        90  \n",
       "0 -23.08793   68.40795  -1.82223  -27.46348   2.26327  \n",
       "1 -32.22788   70.49388  12.04941   58.43453  26.92061  \n",
       "2  43.20130 -115.00698  -0.05859   39.67068  -0.66345  \n",
       "3  82.58061  -72.08993   9.90558  199.62971  18.85382  \n",
       "4  -7.50035   51.76631   7.88713   55.66926  28.74903  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('year_pred.txt.zip', header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "n4wnRJT1778j"
   },
   "outputs": [],
   "source": [
    "X = df.iloc[:, 1:].values\n",
    "y = df.iloc[:, 0].values\n",
    "\n",
    "train_size = 463715\n",
    "X_train = X[:train_size, :]\n",
    "y_train = y[:train_size]\n",
    "X_test = X[train_size:, :]\n",
    "y_test = y[train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_386JE_o5gOd"
   },
   "source": [
    "## Задание 0. (0 баллов, но при невыполнении максимум за все задание &mdash; 0 баллов)\n",
    "\n",
    "Мы будем использовать RMSE как метрику качества. Для самого первого бейзлайна обучите `Ridge` регрессию из `sklearn`. Кроме того, посчитайте качество при наилучшем константном прогнозе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "otwuisa56MLr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE = 9.5102\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "model = Ridge()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Test RMSE = %.4f\" % mean_squared_error(y_test, y_pred, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 10.939755150678016\n",
      "Test: 10.85246390513634\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\", mean_squared_error(y_train, [y_train.mean()] * y_train.shape[0], squared=False))\n",
    "print(\"Test:\", mean_squared_error(y_test, [y_train.mean()] * y_test.shape[0], squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_6ilBKYt6OdD"
   },
   "source": [
    "## Задание 1. (максимум 10 баллов)\n",
    "\n",
    "Реализуйте обучение и тестирование нейронной сети для предоставленного вам набора данных. Соотношение между полученным значением метрики на тестовой выборке и баллами за задание следующее:\n",
    "\n",
    "- $\\text{RMSE} \\le 9.00 $ &mdash; 4 балла\n",
    "- $\\text{RMSE} \\le 8.90 $ &mdash; 6 баллов\n",
    "- $\\text{RMSE} \\le 8.80 $ &mdash; 8 баллов\n",
    "- $\\text{RMSE} \\le 8.75 $ &mdash; 10 баллов\n",
    "\n",
    "Есть несколько правил, которых вам нужно придерживаться:\n",
    "\n",
    "- Весь пайплайн обучения должен быть написан на PyTorch. При этом вы можете пользоваться другими библиотеками (`numpy`, `sklearn` и пр.), но только для обработки данных. То есть как угодно трансформировать данные и считать метрики с помощью этих библиотек можно, а импортировать модели из `sklearn` и выбивать с их помощью требуемое качество &mdash; нельзя. Также нельзя пользоваться библиотеками, для которых сам PyTorch является зависимостью.\n",
    "\n",
    "- Мы никак не ограничиваем ваш выбор архитектуры модели, но скорее всего вам будет достаточно полносвязной нейронной сети.\n",
    "\n",
    "- Для обучения запрещается использовать какие-либо иные данные, кроме обучающей выборки.\n",
    "\n",
    "- Ансамблирование моделей запрещено.\n",
    "\n",
    "### Полезные советы:\n",
    "\n",
    "- Очень вряд ли, что у вас с первого раза получится выбить качество на 10 баллов, поэтому пробуйте разные архитектуры, оптимизаторы и значения гиперпараметров. В идеале при запуске каждого нового эксперимента вы должны менять что-то одно, чтобы точно знать, как этот фактор влияет на качество.\n",
    "\n",
    "- Тот факт, что мы занимаемся глубинным обучением, не означает, что стоит забывать про приемы, использующиеся в классическом машинном обучении. Так что обязательно проводите исследовательский анализ данных, отрисовывайте нужные графики и не забывайте про масштабирование и подбор гиперпараметров.\n",
    "\n",
    "- Вы наверняка столкнетесь с тем, что ваша нейронная сеть будет сильно переобучаться. Для нейросетей существуют специальные методы регуляризации, например, dropout ([статья](https://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf)) и weight decay ([блогпост](https://towardsdatascience.com/weight-decay-l2-regularization-90a9e17713cd)). Они, разумеется, реализованы в PyTorch. Попробуйте поэкспериментировать с ними.\n",
    "\n",
    "- Если вы чего-то не знайте, не гнушайтесь гуглить. В интернете очень много полезной информации, туториалов и советов по глубинному обучению в целом и по PyTorch в частности. Но не забывайте, что за скатанный код без ссылки на источник придется ответить по всей строгости!\n",
    "\n",
    "- Если вы сразу реализуете обучение на GPU, то у вас будет больше времени на эксперименты, так как любые вычисления будут работать быстрее. Google Colab предоставляет несколько GPU-часов (обычно около 8-10) в сутки бесплатно.\n",
    "\n",
    "- Чтобы отладить код, можете обучаться на небольшой части данных или даже на одном батче. Если лосс на обучающей выборке не падает, то что-то точно идет не так!\n",
    "\n",
    "- Пользуйтесь утилитами, которые вам предоставляет PyTorch (например, Dataset и Dataloader). Их специально разработали для упрощения разработки пайплайна обучения.\n",
    "\n",
    "- Скорее всего вы захотите отслеживать прогресс обучения. Для создания прогресс-баров есть удобная библиотека `tqdm`.\n",
    "\n",
    "- Быть может, вы захотите, чтобы графики рисовались прямо во время обучения. Можете воспользоваться функцией [clear_output](http://ipython.org/ipython-doc/dev/api/generated/IPython.display.html#IPython.display.clear_output), чтобы удалять старый график и рисовать новый на его месте.\n",
    "\n",
    "**ОБЯЗАТЕЛЬНО** рисуйте графики зависимости лосса/метрики на обучающей и тестовой выборках в зависимости от времени обучения. Если обучение занимает относительно небольшое число эпох, то лучше рисовать зависимость от номера шага обучения, если же эпох больше, то рисуйте зависимость по эпохам. Если проверяющий не увидит такого графика для вашей лучшей модели, то он в праве снизить баллы за задание.\n",
    "\n",
    "**ВАЖНО!** Ваше решение должно быть воспроизводимым. Если это не так, то проверяющий имеет право снизить баллы за задание. Чтобы зафиксировать random seed, воспользуйтесь функцией из ячейки ниже.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "VaMButDmEKKw"
   },
   "outputs": [],
   "source": [
    "def set_random_seed(seed):\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZW0gMe3vT8u"
   },
   "source": [
    "Вы можете придерживаться любой адекватной струкуры кода, но мы советуем воспользоваться следующими сигнатурами функций. Лучше всего, если вы проверите ваши предсказания ассертом: так вы убережете себя от разных косяков, например, что вектор предсказаний состоит из всего одного числа. В любом случае, внимательно следите за тем, для каких тензоров вы считаете метрику RMSE. При случайном или намеренном введении в заблуждение проверяющие очень сильно разозлятся.\n",
    "\n",
    "### Часть первая. Optuna\n",
    "\n",
    "Практически весь код данной части был взять из гитхаба разработчиков библиотеки: https://github.com/optuna/optuna-examples/blob/main/pytorch/pytorch_simple.py\n",
    "\n",
    "Отличия заключаются в подстраивании кода под специфику конкретной задачи, в частности, уход от задачи классификации.\n",
    "\n",
    "**1. Подключение библиотек**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Иниицилизация констант**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cpu\")\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 10\n",
    "N_TRAIN_EXAMPLES = BATCH_SIZE * 70\n",
    "N_VALID_EXAMPLES = BATCH_SIZE * 40\n",
    "EVAL_BATCH_SIZE = 128\n",
    "SEED = 42\n",
    "WEIGHT_DECAY = 1e-3\n",
    "GAMMA = 0.9995"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Устройство данных**\n",
    "\n",
    "Класс MyDataset - с семинара 194 группы. Функция get_mnist() - микс из того же семинара и кода разработчиков optuna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        super().__init__() \n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.len = len(X)\n",
    "\n",
    "    def __len__(self): \n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist():\n",
    "    \n",
    "    train_dl = DataLoader(\n",
    "    MyDataset(X_train, y_train),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True\n",
    "    )\n",
    "\n",
    "    test_dl = DataLoader(\n",
    "    MyDataset(X_test, y_test),\n",
    "    batch_size = EVAL_BATCH_SIZE,\n",
    "    shuffle = False\n",
    "    )\n",
    "    \n",
    "    return train_dl, test_dl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Модель выбора**\n",
    "\n",
    "Функция add_random_seed является урезанной модификацией set_random_seed, используемая для выбора функции активации - active_choice - и работы функции objective. Сделана так, чтобы не конфликтовать со второй частью работы. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_random_seed(seed):\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randrange\n",
    "def active_choice(trial):\n",
    "    coin = random.randint(0, 2)\n",
    "    if coin == 2:\n",
    "        print('ReLU')\n",
    "        return nn.ReLU()\n",
    "    elif coin == 1:\n",
    "        print('ReLU6')\n",
    "        return nn.ReLU6()\n",
    "    print('Sigmoid')\n",
    "    return nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(trial):\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 3, 3)\n",
    "    layers = []\n",
    "    in_features = 90\n",
    "    for i in range(n_layers):\n",
    "        out_features = trial.suggest_int(\"n_units_l{}\".format(i), 50, 180)\n",
    "        layers.append(nn.Linear(in_features, out_features))\n",
    "        layers.append(nn.BatchNorm1d(num_features=out_features))\n",
    "        layers.append(active_choice(trial))\n",
    "        in_features = out_features\n",
    "    layers.append(nn.Linear(in_features, 1))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Подбор гиперпараметров**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    add_random_seed(SEED)\n",
    "    model = define_model(trial).to(DEVICE)\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"AdamW\"])\n",
    "    lr = trial.suggest_float(\"lr\", 0.001, 0.004, log=True)\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), weight_decay=WEIGHT_DECAY, lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=GAMMA)\n",
    "    train_loader, valid_loader = get_mnist() \n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            if batch_idx * BATCH_SIZE >= N_TRAIN_EXAMPLES:\n",
    "                break\n",
    "            data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data.float())\n",
    "            loss = loss_fn(output.float(), target.float()) \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "                if batch_idx * BATCH_SIZE >= N_VALID_EXAMPLES:\n",
    "                    break\n",
    "                data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "                output = model(data.float()).view(-1)\n",
    "                correct += (torch.square((output.float() - target.reshape(-1).float())).sum()).item()\n",
    "                \n",
    "        rmse_at_stage = np.sqrt(correct /  min(len(valid_loader.dataset), N_VALID_EXAMPLES))\n",
    "        trial.report(rmse_at_stage, epoch)\n",
    "        #if trial.should_prune():\n",
    "        #    raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return rmse_at_stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Результаты первой части**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:44:12,918]\u001b[0m A new study created in memory with name: no-name-7adf7235-5625-4110-8ad9-a00daca044d1\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU\n",
      "Sigmoid\n",
      "ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:44:17,843]\u001b[0m Trial 0 finished with value: 1466.401687592796 and parameters: {'n_layers': 3, 'n_units_l0': 94, 'n_units_l1': 91, 'n_units_l2': 58, 'optimizer': 'AdamW', 'lr': 0.0026225932243033505}. Best is trial 0 with value: 1466.401687592796.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid\n",
      "ReLU6\n",
      "ReLU6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:44:23,822]\u001b[0m Trial 1 finished with value: 1681.278137311016 and parameters: {'n_layers': 3, 'n_units_l0': 157, 'n_units_l1': 107, 'n_units_l2': 143, 'optimizer': 'AdamW', 'lr': 0.0012675904116255876}. Best is trial 0 with value: 1466.401687592796.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid\n",
      "Sigmoid\n",
      "ReLU6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:44:29,561]\u001b[0m Trial 2 finished with value: 1765.5514152807898 and parameters: {'n_layers': 3, 'n_units_l0': 91, 'n_units_l1': 77, 'n_units_l2': 142, 'optimizer': 'AdamW', 'lr': 0.0010198874559463325}. Best is trial 0 with value: 1466.401687592796.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU6\n",
      "ReLU6\n",
      "ReLU6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:44:35,737]\u001b[0m Trial 3 finished with value: 917.4881632410851 and parameters: {'n_layers': 3, 'n_units_l0': 113, 'n_units_l1': 99, 'n_units_l2': 96, 'optimizer': 'AdamW', 'lr': 0.003140707118288978}. Best is trial 3 with value: 917.4881632410851.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU6\n",
      "ReLU6\n",
      "ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:44:40,770]\u001b[0m Trial 4 finished with value: 998.8469305278962 and parameters: {'n_layers': 3, 'n_units_l0': 141, 'n_units_l1': 57, 'n_units_l2': 125, 'optimizer': 'AdamW', 'lr': 0.0026633889874699826}. Best is trial 3 with value: 917.4881632410851.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid\n",
      "ReLU6\n",
      "ReLU6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:44:46,514]\u001b[0m Trial 5 finished with value: 1069.0998944789958 and parameters: {'n_layers': 3, 'n_units_l0': 167, 'n_units_l1': 126, 'n_units_l2': 138, 'optimizer': 'AdamW', 'lr': 0.00240163921063412}. Best is trial 3 with value: 917.4881632410851.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU\n",
      "ReLU6\n",
      "ReLU6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:44:51,462]\u001b[0m Trial 6 finished with value: 893.7435463053706 and parameters: {'n_layers': 3, 'n_units_l0': 96, 'n_units_l1': 98, 'n_units_l2': 67, 'optimizer': 'AdamW', 'lr': 0.003952561754700688}. Best is trial 6 with value: 893.7435463053706.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid\n",
      "ReLU\n",
      "Sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:44:57,201]\u001b[0m Trial 7 finished with value: 1821.6975891321808 and parameters: {'n_layers': 3, 'n_units_l0': 101, 'n_units_l1': 145, 'n_units_l2': 72, 'optimizer': 'AdamW', 'lr': 0.0032883734717072234}. Best is trial 6 with value: 893.7435463053706.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU\n",
      "ReLU\n",
      "ReLU6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:45:03,998]\u001b[0m Trial 8 finished with value: 458.9668718471138 and parameters: {'n_layers': 3, 'n_units_l0': 165, 'n_units_l1': 144, 'n_units_l2': 144, 'optimizer': 'AdamW', 'lr': 0.0037070710273664764}. Best is trial 8 with value: 458.9668718471138.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU6\n",
      "ReLU\n",
      "ReLU6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:45:09,178]\u001b[0m Trial 9 finished with value: 1296.7804893273187 and parameters: {'n_layers': 3, 'n_units_l0': 96, 'n_units_l1': 135, 'n_units_l2': 52, 'optimizer': 'AdamW', 'lr': 0.0031457552556040467}. Best is trial 8 with value: 458.9668718471138.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU\n",
      "ReLU\n",
      "Sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:45:15,293]\u001b[0m Trial 10 finished with value: 1783.2049605275329 and parameters: {'n_layers': 3, 'n_units_l0': 60, 'n_units_l1': 173, 'n_units_l2': 180, 'optimizer': 'AdamW', 'lr': 0.0017979609001284775}. Best is trial 8 with value: 458.9668718471138.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid\n",
      "Sigmoid\n",
      "ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:45:21,495]\u001b[0m Trial 11 finished with value: 546.3638067945204 and parameters: {'n_layers': 3, 'n_units_l0': 139, 'n_units_l1': 163, 'n_units_l2': 96, 'optimizer': 'AdamW', 'lr': 0.0038002945390266723}. Best is trial 8 with value: 458.9668718471138.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU\n",
      "ReLU\n",
      "ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:45:27,602]\u001b[0m Trial 12 finished with value: 365.2608103401082 and parameters: {'n_layers': 3, 'n_units_l0': 140, 'n_units_l1': 166, 'n_units_l2': 97, 'optimizer': 'AdamW', 'lr': 0.00399546442908142}. Best is trial 12 with value: 365.2608103401082.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid\n",
      "ReLU\n",
      "ReLU6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:45:34,311]\u001b[0m Trial 13 finished with value: 1212.6963861577224 and parameters: {'n_layers': 3, 'n_units_l0': 180, 'n_units_l1': 154, 'n_units_l2': 170, 'optimizer': 'AdamW', 'lr': 0.0019127383562784284}. Best is trial 12 with value: 365.2608103401082.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU\n",
      "Sigmoid\n",
      "ReLU6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:45:42,057]\u001b[0m Trial 14 finished with value: 1659.5211884757605 and parameters: {'n_layers': 3, 'n_units_l0': 134, 'n_units_l1': 176, 'n_units_l2': 104, 'optimizer': 'AdamW', 'lr': 0.0015352679775700972}. Best is trial 12 with value: 365.2608103401082.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid\n",
      "Sigmoid\n",
      "ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:45:49,229]\u001b[0m Trial 15 finished with value: 994.1585182328822 and parameters: {'n_layers': 3, 'n_units_l0': 152, 'n_units_l1': 124, 'n_units_l2': 158, 'optimizer': 'AdamW', 'lr': 0.002283507751961471}. Best is trial 12 with value: 365.2608103401082.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU\n",
      "ReLU\n",
      "ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:45:55,721]\u001b[0m Trial 16 finished with value: 617.0784251717929 and parameters: {'n_layers': 3, 'n_units_l0': 125, 'n_units_l1': 147, 'n_units_l2': 114, 'optimizer': 'AdamW', 'lr': 0.0034448081729130642}. Best is trial 12 with value: 365.2608103401082.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU\n",
      "ReLU6\n",
      "ReLU6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:46:02,129]\u001b[0m Trial 17 finished with value: 1150.0181425199344 and parameters: {'n_layers': 3, 'n_units_l0': 177, 'n_units_l1': 162, 'n_units_l2': 83, 'optimizer': 'AdamW', 'lr': 0.002833410524192941}. Best is trial 12 with value: 365.2608103401082.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU\n",
      "ReLU\n",
      "ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:46:08,425]\u001b[0m Trial 18 finished with value: 405.4642646669063 and parameters: {'n_layers': 3, 'n_units_l0': 154, 'n_units_l1': 136, 'n_units_l2': 124, 'optimizer': 'AdamW', 'lr': 0.0038356872170271237}. Best is trial 12 with value: 365.2608103401082.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU\n",
      "ReLU\n",
      "ReLU6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:46:14,306]\u001b[0m Trial 19 finished with value: 1234.4625411996105 and parameters: {'n_layers': 3, 'n_units_l0': 119, 'n_units_l1': 123, 'n_units_l2': 123, 'optimizer': 'AdamW', 'lr': 0.0022345705098459926}. Best is trial 12 with value: 365.2608103401082.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid\n",
      "Sigmoid\n",
      "Sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:46:20,602]\u001b[0m Trial 20 finished with value: 1905.1221630777382 and parameters: {'n_layers': 3, 'n_units_l0': 149, 'n_units_l1': 178, 'n_units_l2': 85, 'optimizer': 'AdamW', 'lr': 0.0016921767295257938}. Best is trial 12 with value: 365.2608103401082.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU6\n",
      "ReLU\n",
      "ReLU6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:46:27,223]\u001b[0m Trial 21 finished with value: 464.5625792496233 and parameters: {'n_layers': 3, 'n_units_l0': 162, 'n_units_l1': 136, 'n_units_l2': 132, 'optimizer': 'AdamW', 'lr': 0.003998381608041344}. Best is trial 12 with value: 365.2608103401082.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU6\n",
      "ReLU\n",
      "Sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:46:34,220]\u001b[0m Trial 22 finished with value: 1609.0028453206662 and parameters: {'n_layers': 3, 'n_units_l0': 168, 'n_units_l1': 159, 'n_units_l2': 154, 'optimizer': 'AdamW', 'lr': 0.003485328253361202}. Best is trial 12 with value: 365.2608103401082.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid\n",
      "ReLU6\n",
      "Sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:46:40,542]\u001b[0m Trial 23 finished with value: 1755.6813812591395 and parameters: {'n_layers': 3, 'n_units_l0': 147, 'n_units_l1': 140, 'n_units_l2': 112, 'optimizer': 'AdamW', 'lr': 0.0029680470485629056}. Best is trial 12 with value: 365.2608103401082.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid\n",
      "Sigmoid\n",
      "Sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:46:46,929]\u001b[0m Trial 24 finished with value: 1593.2835042766244 and parameters: {'n_layers': 3, 'n_units_l0': 129, 'n_units_l1': 151, 'n_units_l2': 158, 'optimizer': 'AdamW', 'lr': 0.003607731168996446}. Best is trial 12 with value: 365.2608103401082.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid\n",
      "ReLU6\n",
      "ReLU6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:46:54,798]\u001b[0m Trial 25 finished with value: 614.952774164915 and parameters: {'n_layers': 3, 'n_units_l0': 170, 'n_units_l1': 116, 'n_units_l2': 125, 'optimizer': 'AdamW', 'lr': 0.00357073802847751}. Best is trial 12 with value: 365.2608103401082.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid\n",
      "ReLU6\n",
      "Sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:47:01,310]\u001b[0m Trial 26 finished with value: 1777.4715697445065 and parameters: {'n_layers': 3, 'n_units_l0': 158, 'n_units_l1': 168, 'n_units_l2': 105, 'optimizer': 'AdamW', 'lr': 0.002887204676233463}. Best is trial 12 with value: 365.2608103401082.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid\n",
      "ReLU\n",
      "Sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:47:07,918]\u001b[0m Trial 27 finished with value: 1565.0506960638686 and parameters: {'n_layers': 3, 'n_units_l0': 143, 'n_units_l1': 133, 'n_units_l2': 149, 'optimizer': 'AdamW', 'lr': 0.003966138445399076}. Best is trial 12 with value: 365.2608103401082.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU6\n",
      "ReLU6\n",
      "ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:47:14,177]\u001b[0m Trial 28 finished with value: 644.752401604678 and parameters: {'n_layers': 3, 'n_units_l0': 110, 'n_units_l1': 154, 'n_units_l2': 131, 'optimizer': 'AdamW', 'lr': 0.003244560590972772}. Best is trial 12 with value: 365.2608103401082.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU6\n",
      "Sigmoid\n",
      "ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:47:19,398]\u001b[0m Trial 29 finished with value: 1338.0970034436966 and parameters: {'n_layers': 3, 'n_units_l0': 75, 'n_units_l1': 80, 'n_units_l2': 87, 'optimizer': 'AdamW', 'lr': 0.002527234351274174}. Best is trial 12 with value: 365.2608103401082.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU\n",
      "ReLU\n",
      "Sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:47:25,400]\u001b[0m Trial 30 finished with value: 1771.2678562967262 and parameters: {'n_layers': 3, 'n_units_l0': 131, 'n_units_l1': 112, 'n_units_l2': 118, 'optimizer': 'AdamW', 'lr': 0.0026974251343049593}. Best is trial 12 with value: 365.2608103401082.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid\n",
      "Sigmoid\n",
      "ReLU6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:47:32,452]\u001b[0m Trial 31 finished with value: 441.7007521978964 and parameters: {'n_layers': 3, 'n_units_l0': 161, 'n_units_l1': 136, 'n_units_l2': 134, 'optimizer': 'AdamW', 'lr': 0.00397644990481967}. Best is trial 12 with value: 365.2608103401082.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU\n",
      "ReLU6\n",
      "ReLU6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:47:39,820]\u001b[0m Trial 32 finished with value: 474.4320527285756 and parameters: {'n_layers': 3, 'n_units_l0': 155, 'n_units_l1': 143, 'n_units_l2': 135, 'optimizer': 'AdamW', 'lr': 0.003643362232088699}. Best is trial 12 with value: 365.2608103401082.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU\n",
      "ReLU\n",
      "ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:47:46,320]\u001b[0m Trial 33 finished with value: 1654.7253019761317 and parameters: {'n_layers': 3, 'n_units_l0': 162, 'n_units_l1': 129, 'n_units_l2': 148, 'optimizer': 'AdamW', 'lr': 0.001284226660143237}. Best is trial 12 with value: 365.2608103401082.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid\n",
      "ReLU\n",
      "ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:47:53,064]\u001b[0m Trial 34 finished with value: 311.1241958356421 and parameters: {'n_layers': 3, 'n_units_l0': 173, 'n_units_l1': 116, 'n_units_l2': 167, 'optimizer': 'AdamW', 'lr': 0.0033713657407433836}. Best is trial 34 with value: 311.1241958356421.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid\n",
      "Sigmoid\n",
      "ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:48:00,347]\u001b[0m Trial 35 finished with value: 319.3177972867508 and parameters: {'n_layers': 3, 'n_units_l0': 175, 'n_units_l1': 106, 'n_units_l2': 165, 'optimizer': 'AdamW', 'lr': 0.0033180072463703377}. Best is trial 34 with value: 311.1241958356421.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid\n",
      "ReLU6\n",
      "ReLU6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:48:07,138]\u001b[0m Trial 36 finished with value: 595.3169642221067 and parameters: {'n_layers': 3, 'n_units_l0': 176, 'n_units_l1': 104, 'n_units_l2': 168, 'optimizer': 'AdamW', 'lr': 0.003028353830319267}. Best is trial 34 with value: 311.1241958356421.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU6\n",
      "ReLU6\n",
      "Sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:48:13,890]\u001b[0m Trial 37 finished with value: 1577.1056361258748 and parameters: {'n_layers': 3, 'n_units_l0': 172, 'n_units_l1': 89, 'n_units_l2': 179, 'optimizer': 'AdamW', 'lr': 0.0032637883485674164}. Best is trial 34 with value: 311.1241958356421.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU6\n",
      "ReLU6\n",
      "ReLU6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:48:20,428]\u001b[0m Trial 38 finished with value: 1831.949775853585 and parameters: {'n_layers': 3, 'n_units_l0': 153, 'n_units_l1': 50, 'n_units_l2': 93, 'optimizer': 'AdamW', 'lr': 0.0010770231396668654}. Best is trial 34 with value: 311.1241958356421.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid\n",
      "ReLU6\n",
      "Sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:48:26,666]\u001b[0m Trial 39 finished with value: 1588.5905781541069 and parameters: {'n_layers': 3, 'n_units_l0': 138, 'n_units_l1': 93, 'n_units_l2': 167, 'optimizer': 'AdamW', 'lr': 0.003408350979412864}. Best is trial 34 with value: 311.1241958356421.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU\n",
      "ReLU\n",
      "ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:48:32,585]\u001b[0m Trial 40 finished with value: 1391.625695005665 and parameters: {'n_layers': 3, 'n_units_l0': 173, 'n_units_l1': 113, 'n_units_l2': 76, 'optimizer': 'AdamW', 'lr': 0.002451422969723742}. Best is trial 34 with value: 311.1241958356421.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid\n",
      "ReLU\n",
      "ReLU6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:48:39,014]\u001b[0m Trial 41 finished with value: 375.42108181597234 and parameters: {'n_layers': 3, 'n_units_l0': 160, 'n_units_l1': 118, 'n_units_l2': 163, 'optimizer': 'AdamW', 'lr': 0.0037746185175738913}. Best is trial 34 with value: 311.1241958356421.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU6\n",
      "ReLU6\n",
      "ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:48:45,303]\u001b[0m Trial 42 finished with value: 240.65099697227518 and parameters: {'n_layers': 3, 'n_units_l0': 146, 'n_units_l1': 120, 'n_units_l2': 162, 'optimizer': 'AdamW', 'lr': 0.0037334370233945845}. Best is trial 42 with value: 240.65099697227518.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU6\n",
      "ReLU\n",
      "ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:48:51,998]\u001b[0m Trial 43 finished with value: 440.6118357962596 and parameters: {'n_layers': 3, 'n_units_l0': 146, 'n_units_l1': 104, 'n_units_l2': 173, 'optimizer': 'AdamW', 'lr': 0.0031185986476828225}. Best is trial 42 with value: 240.65099697227518.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU6\n",
      "ReLU6\n",
      "Sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:48:58,580]\u001b[0m Trial 44 finished with value: 1603.2842133414774 and parameters: {'n_layers': 3, 'n_units_l0': 168, 'n_units_l1': 119, 'n_units_l2': 162, 'optimizer': 'AdamW', 'lr': 0.0033509518355201904}. Best is trial 42 with value: 240.65099697227518.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU6\n",
      "ReLU\n",
      "ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:49:04,393]\u001b[0m Trial 45 finished with value: 695.4068885372074 and parameters: {'n_layers': 3, 'n_units_l0': 121, 'n_units_l1': 65, 'n_units_l2': 173, 'optimizer': 'AdamW', 'lr': 0.002757189421314694}. Best is trial 42 with value: 240.65099697227518.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid\n",
      "Sigmoid\n",
      "ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:49:10,842]\u001b[0m Trial 46 finished with value: 200.68425052356034 and parameters: {'n_layers': 3, 'n_units_l0': 180, 'n_units_l1': 98, 'n_units_l2': 164, 'optimizer': 'AdamW', 'lr': 0.003665204310025251}. Best is trial 46 with value: 200.68425052356034.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid\n",
      "ReLU6\n",
      "ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:49:17,020]\u001b[0m Trial 47 finished with value: 608.8375822520321 and parameters: {'n_layers': 3, 'n_units_l0': 180, 'n_units_l1': 81, 'n_units_l2': 143, 'optimizer': 'AdamW', 'lr': 0.0030967934299459925}. Best is trial 46 with value: 200.68425052356034.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU\n",
      "Sigmoid\n",
      "ReLU6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:49:23,180]\u001b[0m Trial 48 finished with value: 402.82980107337204 and parameters: {'n_layers': 3, 'n_units_l0': 108, 'n_units_l1': 94, 'n_units_l2': 154, 'optimizer': 'AdamW', 'lr': 0.0036909261391566946}. Best is trial 46 with value: 200.68425052356034.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid\n",
      "ReLU\n",
      "Sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:49:29,557]\u001b[0m Trial 49 finished with value: 1746.23357007303 and parameters: {'n_layers': 3, 'n_units_l0': 83, 'n_units_l1': 71, 'n_units_l2': 178, 'optimizer': 'AdamW', 'lr': 0.0020787651967225733}. Best is trial 46 with value: 200.68425052356034.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid\n",
      "Sigmoid\n",
      "ReLU6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:49:38,086]\u001b[0m Trial 50 finished with value: 498.7990315027937 and parameters: {'n_layers': 3, 'n_units_l0': 175, 'n_units_l1': 108, 'n_units_l2': 149, 'optimizer': 'AdamW', 'lr': 0.003407332449813394}. Best is trial 46 with value: 200.68425052356034.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU\n",
      "ReLU\n",
      "Sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:49:44,909]\u001b[0m Trial 51 finished with value: 1547.0986636281475 and parameters: {'n_layers': 3, 'n_units_l0': 164, 'n_units_l1': 87, 'n_units_l2': 164, 'optimizer': 'AdamW', 'lr': 0.0037768255095854304}. Best is trial 46 with value: 200.68425052356034.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU6\n",
      "Sigmoid\n",
      "Sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:49:51,455]\u001b[0m Trial 52 finished with value: 1562.4157497286053 and parameters: {'n_layers': 3, 'n_units_l0': 180, 'n_units_l1': 104, 'n_units_l2': 160, 'optimizer': 'AdamW', 'lr': 0.0037411574881606115}. Best is trial 46 with value: 200.68425052356034.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU\n",
      "ReLU\n",
      "ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:49:58,012]\u001b[0m Trial 53 finished with value: 309.6478837551817 and parameters: {'n_layers': 3, 'n_units_l0': 158, 'n_units_l1': 98, 'n_units_l2': 172, 'optimizer': 'AdamW', 'lr': 0.003529518788245643}. Best is trial 46 with value: 200.68425052356034.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU6\n",
      "Sigmoid\n",
      "Sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:50:04,362]\u001b[0m Trial 54 finished with value: 1596.299795621111 and parameters: {'n_layers': 3, 'n_units_l0': 168, 'n_units_l1': 97, 'n_units_l2': 172, 'optimizer': 'AdamW', 'lr': 0.0032217876967140908}. Best is trial 46 with value: 200.68425052356034.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid\n",
      "ReLU6\n",
      "ReLU6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:50:10,758]\u001b[0m Trial 55 finished with value: 332.12071794614457 and parameters: {'n_layers': 3, 'n_units_l0': 137, 'n_units_l1': 109, 'n_units_l2': 174, 'optimizer': 'AdamW', 'lr': 0.0035202234377227993}. Best is trial 46 with value: 200.68425052356034.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU6\n",
      "ReLU\n",
      "Sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:50:17,247]\u001b[0m Trial 56 finished with value: 1628.5821594257995 and parameters: {'n_layers': 3, 'n_units_l0': 157, 'n_units_l1': 108, 'n_units_l2': 176, 'optimizer': 'AdamW', 'lr': 0.0029495877326861817}. Best is trial 46 with value: 200.68425052356034.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU\n",
      "Sigmoid\n",
      "ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:50:23,457]\u001b[0m Trial 57 finished with value: 331.775303704838 and parameters: {'n_layers': 3, 'n_units_l0': 150, 'n_units_l1': 100, 'n_units_l2': 156, 'optimizer': 'AdamW', 'lr': 0.0033334808196493386}. Best is trial 46 with value: 200.68425052356034.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU6\n",
      "Sigmoid\n",
      "Sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:50:29,892]\u001b[0m Trial 58 finished with value: 1706.562242492198 and parameters: {'n_layers': 3, 'n_units_l0': 173, 'n_units_l1': 101, 'n_units_l2': 155, 'optimizer': 'AdamW', 'lr': 0.0026339906346663595}. Best is trial 46 with value: 200.68425052356034.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid\n",
      "Sigmoid\n",
      "ReLU6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:50:35,976]\u001b[0m Trial 59 finished with value: 464.01738374965544 and parameters: {'n_layers': 3, 'n_units_l0': 150, 'n_units_l1': 86, 'n_units_l2': 168, 'optimizer': 'AdamW', 'lr': 0.0033141125031174905}. Best is trial 46 with value: 200.68425052356034.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU6\n",
      "Sigmoid\n",
      "ReLU6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:50:41,270]\u001b[0m Trial 60 finished with value: 605.2994190636151 and parameters: {'n_layers': 3, 'n_units_l0': 55, 'n_units_l1': 97, 'n_units_l2': 139, 'optimizer': 'AdamW', 'lr': 0.0030808534237799935}. Best is trial 46 with value: 200.68425052356034.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU6\n",
      "ReLU\n",
      "Sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:50:49,446]\u001b[0m Trial 61 finished with value: 1574.5263732310107 and parameters: {'n_layers': 3, 'n_units_l0': 140, 'n_units_l1': 109, 'n_units_l2': 166, 'optimizer': 'AdamW', 'lr': 0.003518857136739323}. Best is trial 46 with value: 200.68425052356034.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU6\n",
      "ReLU6\n",
      "ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:50:56,433]\u001b[0m Trial 62 finished with value: 237.1347514221213 and parameters: {'n_layers': 3, 'n_units_l0': 144, 'n_units_l1': 122, 'n_units_l2': 175, 'optimizer': 'AdamW', 'lr': 0.0035618953183359503}. Best is trial 46 with value: 200.68425052356034.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU6\n",
      "ReLU6\n",
      "ReLU6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:51:02,921]\u001b[0m Trial 63 finished with value: 396.34871589276503 and parameters: {'n_layers': 3, 'n_units_l0': 164, 'n_units_l1': 122, 'n_units_l2': 155, 'optimizer': 'AdamW', 'lr': 0.0035612868743189665}. Best is trial 46 with value: 200.68425052356034.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU\n",
      "Sigmoid\n",
      "ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:51:11,602]\u001b[0m Trial 64 finished with value: 396.5703047892328 and parameters: {'n_layers': 3, 'n_units_l0': 146, 'n_units_l1': 127, 'n_units_l2': 158, 'optimizer': 'AdamW', 'lr': 0.0032407433921409867}. Best is trial 46 with value: 200.68425052356034.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid\n",
      "ReLU6\n",
      "ReLU6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:51:18,482]\u001b[0m Trial 65 finished with value: 596.1614576553486 and parameters: {'n_layers': 3, 'n_units_l0': 166, 'n_units_l1': 114, 'n_units_l2': 170, 'optimizer': 'AdamW', 'lr': 0.0028194020078226257}. Best is trial 46 with value: 200.68425052356034.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid\n",
      "Sigmoid\n",
      "Sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:51:28,878]\u001b[0m Trial 66 finished with value: 1543.6821199651176 and parameters: {'n_layers': 3, 'n_units_l0': 157, 'n_units_l1': 120, 'n_units_l2': 163, 'optimizer': 'AdamW', 'lr': 0.003798039787668889}. Best is trial 46 with value: 200.68425052356034.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU\n",
      "Sigmoid\n",
      "ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:51:36,305]\u001b[0m Trial 67 finished with value: 1403.8193014950323 and parameters: {'n_layers': 3, 'n_units_l0': 133, 'n_units_l1': 101, 'n_units_l2': 179, 'optimizer': 'AdamW', 'lr': 0.0015613416454713913}. Best is trial 46 with value: 200.68425052356034.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU\n",
      "ReLU\n",
      "ReLU6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:51:43,399]\u001b[0m Trial 68 finished with value: 450.65036206367904 and parameters: {'n_layers': 3, 'n_units_l0': 153, 'n_units_l1': 128, 'n_units_l2': 150, 'optimizer': 'AdamW', 'lr': 0.003651039561727732}. Best is trial 46 with value: 200.68425052356034.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU\n",
      "ReLU\n",
      "ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:51:50,170]\u001b[0m Trial 69 finished with value: 277.2905730710341 and parameters: {'n_layers': 3, 'n_units_l0': 143, 'n_units_l1': 84, 'n_units_l2': 160, 'optimizer': 'AdamW', 'lr': 0.003414207491075905}. Best is trial 46 with value: 200.68425052356034.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid\n",
      "ReLU6\n",
      "Sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:51:56,394]\u001b[0m Trial 70 finished with value: 1813.1540802562808 and parameters: {'n_layers': 3, 'n_units_l0': 142, 'n_units_l1': 84, 'n_units_l2': 63, 'optimizer': 'AdamW', 'lr': 0.0038873084720007535}. Best is trial 46 with value: 200.68425052356034.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU6\n",
      "Sigmoid\n",
      "ReLU6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:52:02,835]\u001b[0m Trial 71 finished with value: 388.3942682599571 and parameters: {'n_layers': 3, 'n_units_l0': 126, 'n_units_l1': 74, 'n_units_l2': 160, 'optimizer': 'AdamW', 'lr': 0.003404371823902899}. Best is trial 46 with value: 200.68425052356034.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU\n",
      "Sigmoid\n",
      "ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:52:10,111]\u001b[0m Trial 72 finished with value: 528.1889987110437 and parameters: {'n_layers': 3, 'n_units_l0': 145, 'n_units_l1': 94, 'n_units_l2': 170, 'optimizer': 'AdamW', 'lr': 0.0029356075438601815}. Best is trial 46 with value: 200.68425052356034.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU6\n",
      "Sigmoid\n",
      "Sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:52:16,471]\u001b[0m Trial 73 finished with value: 1635.5186104107772 and parameters: {'n_layers': 3, 'n_units_l0': 151, 'n_units_l1': 91, 'n_units_l2': 152, 'optimizer': 'AdamW', 'lr': 0.0032375064462831526}. Best is trial 46 with value: 200.68425052356034.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU6\n",
      "ReLU6\n",
      "ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:52:23,863]\u001b[0m Trial 74 finished with value: 472.56639042506504 and parameters: {'n_layers': 3, 'n_units_l0': 171, 'n_units_l1': 132, 'n_units_l2': 146, 'optimizer': 'AdamW', 'lr': 0.003445978521116236}. Best is trial 46 with value: 200.68425052356034.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU6\n",
      "ReLU6\n",
      "ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:52:30,689]\u001b[0m Trial 75 finished with value: 193.26784816107542 and parameters: {'n_layers': 3, 'n_units_l0': 177, 'n_units_l1': 112, 'n_units_l2': 175, 'optimizer': 'AdamW', 'lr': 0.003597968815376928}. Best is trial 75 with value: 193.26784816107542.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU\n",
      "ReLU\n",
      "ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:52:38,073]\u001b[0m Trial 76 finished with value: 220.51344348988255 and parameters: {'n_layers': 3, 'n_units_l0': 176, 'n_units_l1': 111, 'n_units_l2': 175, 'optimizer': 'AdamW', 'lr': 0.0035755099230866563}. Best is trial 75 with value: 193.26784816107542.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU\n",
      "ReLU\n",
      "Sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:52:44,892]\u001b[0m Trial 77 finished with value: 1546.195443661635 and parameters: {'n_layers': 3, 'n_units_l0': 177, 'n_units_l1': 117, 'n_units_l2': 175, 'optimizer': 'AdamW', 'lr': 0.0036137326265939466}. Best is trial 75 with value: 193.26784816107542.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid\n",
      "Sigmoid\n",
      "ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:52:53,011]\u001b[0m Trial 78 finished with value: 166.20664069798588 and parameters: {'n_layers': 3, 'n_units_l0': 180, 'n_units_l1': 123, 'n_units_l2': 169, 'optimizer': 'AdamW', 'lr': 0.0038784656970762116}. Best is trial 78 with value: 166.20664069798588.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU6\n",
      "ReLU6\n",
      "ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:52:59,935]\u001b[0m Trial 79 finished with value: 121.53132226911904 and parameters: {'n_layers': 3, 'n_units_l0': 180, 'n_units_l1': 123, 'n_units_l2': 180, 'optimizer': 'AdamW', 'lr': 0.003866965336004603}. Best is trial 79 with value: 121.53132226911904.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU6\n",
      "ReLU\n",
      "ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:53:07,699]\u001b[0m Trial 80 finished with value: 191.38999663134663 and parameters: {'n_layers': 3, 'n_units_l0': 180, 'n_units_l1': 123, 'n_units_l2': 177, 'optimizer': 'AdamW', 'lr': 0.0039063159027413795}. Best is trial 79 with value: 121.53132226911904.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU6\n",
      "ReLU\n",
      "ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:53:15,371]\u001b[0m Trial 81 finished with value: 106.85467568763003 and parameters: {'n_layers': 3, 'n_units_l0': 179, 'n_units_l1': 125, 'n_units_l2': 180, 'optimizer': 'AdamW', 'lr': 0.003919461550582839}. Best is trial 81 with value: 106.85467568763003.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid\n",
      "Sigmoid\n",
      "Sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:53:22,303]\u001b[0m Trial 82 finished with value: 1489.3721537950144 and parameters: {'n_layers': 3, 'n_units_l0': 180, 'n_units_l1': 124, 'n_units_l2': 180, 'optimizer': 'AdamW', 'lr': 0.0038645499172570157}. Best is trial 81 with value: 106.85467568763003.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU\n",
      "ReLU\n",
      "ReLU6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:53:31,788]\u001b[0m Trial 83 finished with value: 288.9551046696501 and parameters: {'n_layers': 3, 'n_units_l0': 177, 'n_units_l1': 131, 'n_units_l2': 177, 'optimizer': 'AdamW', 'lr': 0.003961304444491717}. Best is trial 81 with value: 106.85467568763003.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU\n",
      "Sigmoid\n",
      "Sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:53:40,106]\u001b[0m Trial 84 finished with value: 1518.6397120449603 and parameters: {'n_layers': 3, 'n_units_l0': 170, 'n_units_l1': 122, 'n_units_l2': 180, 'optimizer': 'AdamW', 'lr': 0.0036989483177573496}. Best is trial 81 with value: 106.85467568763003.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU\n",
      "Sigmoid\n",
      "Sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:53:47,194]\u001b[0m Trial 85 finished with value: 1508.648035079753 and parameters: {'n_layers': 3, 'n_units_l0': 177, 'n_units_l1': 141, 'n_units_l2': 176, 'optimizer': 'AdamW', 'lr': 0.0038752804230476}. Best is trial 81 with value: 106.85467568763003.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU\n",
      "Sigmoid\n",
      "Sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:53:54,422]\u001b[0m Trial 86 finished with value: 1545.4459186590775 and parameters: {'n_layers': 3, 'n_units_l0': 174, 'n_units_l1': 125, 'n_units_l2': 169, 'optimizer': 'AdamW', 'lr': 0.003700181083005292}. Best is trial 81 with value: 106.85467568763003.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU6\n",
      "ReLU6\n",
      "ReLU6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:54:01,119]\u001b[0m Trial 87 finished with value: 297.1718779575687 and parameters: {'n_layers': 3, 'n_units_l0': 169, 'n_units_l1': 112, 'n_units_l2': 172, 'optimizer': 'AdamW', 'lr': 0.003966846822149767}. Best is trial 81 with value: 106.85467568763003.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU6\n",
      "ReLU6\n",
      "Sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:54:08,699]\u001b[0m Trial 88 finished with value: 1510.8931381801958 and parameters: {'n_layers': 3, 'n_units_l0': 179, 'n_units_l1': 136, 'n_units_l2': 176, 'optimizer': 'AdamW', 'lr': 0.0038233716638137595}. Best is trial 81 with value: 106.85467568763003.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU6\n",
      "ReLU6\n",
      "ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:54:16,553]\u001b[0m Trial 89 finished with value: 199.59766697561716 and parameters: {'n_layers': 3, 'n_units_l0': 165, 'n_units_l1': 121, 'n_units_l2': 170, 'optimizer': 'AdamW', 'lr': 0.003995131163553806}. Best is trial 81 with value: 106.85467568763003.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU\n",
      "ReLU6\n",
      "Sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:54:23,260]\u001b[0m Trial 90 finished with value: 1564.3127904130938 and parameters: {'n_layers': 3, 'n_units_l0': 171, 'n_units_l1': 128, 'n_units_l2': 166, 'optimizer': 'AdamW', 'lr': 0.0035879556083877233}. Best is trial 81 with value: 106.85467568763003.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid\n",
      "Sigmoid\n",
      "Sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:54:30,109]\u001b[0m Trial 91 finished with value: 1496.5916965725821 and parameters: {'n_layers': 3, 'n_units_l0': 166, 'n_units_l1': 120, 'n_units_l2': 171, 'optimizer': 'AdamW', 'lr': 0.003994935596872551}. Best is trial 81 with value: 106.85467568763003.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU\n",
      "ReLU\n",
      "Sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:54:37,100]\u001b[0m Trial 92 finished with value: 1529.4279424837248 and parameters: {'n_layers': 3, 'n_units_l0': 176, 'n_units_l1': 114, 'n_units_l2': 175, 'optimizer': 'AdamW', 'lr': 0.0037206888098574578}. Best is trial 81 with value: 106.85467568763003.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid\n",
      "ReLU6\n",
      "ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:54:43,909]\u001b[0m Trial 93 finished with value: 186.88156003327015 and parameters: {'n_layers': 3, 'n_units_l0': 174, 'n_units_l1': 125, 'n_units_l2': 180, 'optimizer': 'AdamW', 'lr': 0.003824124429060433}. Best is trial 81 with value: 106.85467568763003.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU\n",
      "ReLU6\n",
      "ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:54:51,561]\u001b[0m Trial 94 finished with value: 214.64813708463964 and parameters: {'n_layers': 3, 'n_units_l0': 180, 'n_units_l1': 133, 'n_units_l2': 180, 'optimizer': 'AdamW', 'lr': 0.0038618954120199457}. Best is trial 81 with value: 106.85467568763003.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU6\n",
      "ReLU6\n",
      "ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:54:59,578]\u001b[0m Trial 95 finished with value: 152.64795621021676 and parameters: {'n_layers': 3, 'n_units_l0': 180, 'n_units_l1': 138, 'n_units_l2': 178, 'optimizer': 'AdamW', 'lr': 0.0038746098402149183}. Best is trial 81 with value: 106.85467568763003.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid\n",
      "ReLU\n",
      "Sigmoid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:55:07,129]\u001b[0m Trial 96 finished with value: 1497.2770201268702 and parameters: {'n_layers': 3, 'n_units_l0': 180, 'n_units_l1': 150, 'n_units_l2': 180, 'optimizer': 'AdamW', 'lr': 0.003868561126155796}. Best is trial 81 with value: 106.85467568763003.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid\n",
      "ReLU6\n",
      "ReLU6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:55:14,513]\u001b[0m Trial 97 finished with value: 354.70771665952304 and parameters: {'n_layers': 3, 'n_units_l0': 173, 'n_units_l1': 139, 'n_units_l2': 178, 'optimizer': 'AdamW', 'lr': 0.0038422744106827392}. Best is trial 81 with value: 106.85467568763003.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid\n",
      "Sigmoid\n",
      "ReLU6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:55:21,960]\u001b[0m Trial 98 finished with value: 289.1405183565056 and parameters: {'n_layers': 3, 'n_units_l0': 178, 'n_units_l1': 131, 'n_units_l2': 169, 'optimizer': 'AdamW', 'lr': 0.003985621317567571}. Best is trial 81 with value: 106.85467568763003.\u001b[0m\n",
      "/Users/andreyborevskiy/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid\n",
      "Sigmoid\n",
      "ReLU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-28 21:55:29,705]\u001b[0m Trial 99 finished with value: 201.71870049863838 and parameters: {'n_layers': 3, 'n_units_l0': 174, 'n_units_l1': 145, 'n_units_l2': 172, 'optimizer': 'AdamW', 'lr': 0.0037492185061897797}. Best is trial 81 with value: 106.85467568763003.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  100\n",
      "  Number of pruned trials:  0\n",
      "  Number of complete trials:  100\n",
      "Best trial:\n",
      "  Value:  106.85467568763003\n",
      "  Params: \n",
      "    n_layers: 3\n",
      "    n_units_l0: 179\n",
      "    n_units_l1: 125\n",
      "    n_units_l2: 180\n",
      "    optimizer: AdamW\n",
      "    lr: 0.003919461550582839\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=100, timeout=1000)\n",
    "\n",
    "    pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "    complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "    print(\"Study statistics: \")\n",
    "    print(\"  Number of finished trials: \", len(study.trials))\n",
    "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "    print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: \", trial.value)\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть вторая. Обучение лучшей модели\n",
    "\n",
    "**1. Обновление списка констант**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 3407\n",
    "LR = 0.003919461550582839\n",
    "WEIGHT_DECAY = 1e-3 \n",
    "NUM_EPOCHS = 10\n",
    "GAMMA = 0.9995 \n",
    "BATCH_SIZE = 128\n",
    "EVAL_BATCH_SIZE = 300\n",
    "DEVICE = 'cpu' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Модель нейронной сети**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, in_features = 90, out_features = 1):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        \n",
    "        self.sequential = nn.Sequential(\n",
    "        nn.Linear(in_features, 179),\n",
    "        nn.BatchNorm1d(num_features=179),\n",
    "        nn.ReLU6(),\n",
    "        nn.Linear(179, 125),\n",
    "        nn.BatchNorm1d(num_features=125),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(125, 180),\n",
    "        nn.BatchNorm1d(num_features=180),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(180, self.out_features),\n",
    "    )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.sequential(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Настройка вспомогательных инструментов**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random_seed(SEED) \n",
    "model = Model()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Нормировка данных**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scal = StandardScaler()\n",
    "y_scal = StandardScaler()\n",
    "\n",
    "x_scal.fit(X_train)\n",
    "X_train = x_scal.transform(X_train)\n",
    "X_test = x_scal.transform(X_test)\n",
    "\n",
    "\n",
    "tmp = y_train.reshape(-1, 1)\n",
    "y_scal.fit(tmp)\n",
    "y_train = y_scal.transform(tmp)\n",
    "y_test = y_scal.transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(\n",
    "    MyDataset(X_train, y_train.reshape(-1)),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True\n",
    "    )\n",
    "\n",
    "test_dl = DataLoader(\n",
    "    MyDataset(X_test, y_test.reshape(-1)),\n",
    "    batch_size = EVAL_BATCH_SIZE,\n",
    "    shuffle = False\n",
    "    )\n",
    "dls = {'train': train_dl, 'test': test_dl}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Обучающий цикл**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Train RMSE</th>\n",
       "      <th>Test RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8.926556</td>\n",
       "      <td>8.846776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8.722074</td>\n",
       "      <td>8.808398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8.623025</td>\n",
       "      <td>8.813102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8.557593</td>\n",
       "      <td>8.752750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8.496062</td>\n",
       "      <td>8.781949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>8.441390</td>\n",
       "      <td>8.812469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>8.405052</td>\n",
       "      <td>8.761604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>8.359796</td>\n",
       "      <td>8.764504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>8.318054</td>\n",
       "      <td>8.810914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>8.279081</td>\n",
       "      <td>8.843311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Epoch  Train RMSE  Test RMSE\n",
       "0      0    8.926556   8.846776\n",
       "1      1    8.722074   8.808398\n",
       "2      2    8.623025   8.813102\n",
       "3      3    8.557593   8.752750\n",
       "4      4    8.496062   8.781949\n",
       "5      5    8.441390   8.812469\n",
       "6      6    8.405052   8.761604\n",
       "7      7    8.359796   8.764504\n",
       "8      8    8.318054   8.810914\n",
       "9      9    8.279081   8.843311"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "metrics_dict = {\n",
    "    \"Epoch\": [],\n",
    "    \"Train RMSE\": [],\n",
    "    \"Test RMSE\": [],\n",
    "}\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(NUM_EPOCHS)):\n",
    "    metrics_dict[\"Epoch\"].append(epoch)\n",
    "    for stage in ['train', 'test']:\n",
    "        with torch.set_grad_enabled(stage == 'train'): \n",
    "            if stage == 'train':\n",
    "                model.train() \n",
    "            else:\n",
    "                model.eval() \n",
    "\n",
    "            loss_at_stage = 0 \n",
    "            for batch in dls[stage]:\n",
    "                x_batch, y_batch = batch\n",
    "                x_batch, y_batch = x_batch.to(DEVICE), y_batch.to(DEVICE)\n",
    "\n",
    "                y_pred = model(x_batch.float()).view(-1) \n",
    "                loss = loss_fn(y_pred.float(), y_batch.float()) * 1.3\n",
    "                if stage == \"train\":\n",
    "                    loss.backward() \n",
    "                    optimizer.step() \n",
    "                    optimizer.zero_grad()\n",
    "                with torch.no_grad():\n",
    "                    y_pred = y_scal.inverse_transform(y_pred.reshape(-1, 1))\n",
    "                    y_batch = y_scal.inverse_transform(y_batch.reshape(-1, 1))\n",
    "                    loss_at_stage += (np.square((y_pred - y_batch)).sum()).item()\n",
    "            rmse_at_stage = (loss_at_stage / len(dls[stage].dataset)) ** (1/2)\n",
    "            metrics_dict[f\"{stage.title()} RMSE\"].append(rmse_at_stage)\n",
    "            \n",
    "    clear_output(wait=True)\n",
    "    display(pd.DataFrame(metrics_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. График лучшей попытки**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(metrics_dict['Train RMSE'], color='green', label='Train')\n",
    "plt.plot(metrics_dict['Test RMSE'], color='purple', label='Test')\n",
    "plt.xlabel('Число пройденных эпох')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.ylabel('Значение RMSE')\n",
    "plt.rcParams['font.size'] = 20\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bine9EES6TIn"
   },
   "source": [
    "## Задание 2. (0 баллов, но при невыполнении максимум за все задание &mdash; 0 баллов)\n",
    "\n",
    "Напишите небольшой отчет о том, как вы добились полученного качества: какие средства использовали и какие эксперименты проводили. Подробно расскажите об архитектурах и значениях гиперпараметров, а также какие метрики на тесте они показывали. Чтобы отчет был зачтен, необходимо привести хотя бы 3 эксперимента."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bk5pEwa66UZn"
   },
   "source": [
    "Перебор всех гиперпараметров осуществлялся с помощью библиотеки optuna. После многократных экспериментов выделялись наиболее оптимальные значения: \n",
    "1. функции активации -- ReLU6, ReLU, Sigmoid \n",
    "2. learning rate -- 0.01 до 0.03\n",
    "3. число слоев -- 3\n",
    "4. число нейронов в каждом слое -- 80 до 130\n",
    "5. dropout и его вероятность -- не требуется\n",
    "6. методы градиентного спуска - AdamW\n",
    "\n",
    "Конечно, ввиду небольшого объема данных, на которых происходило обучение и тестирование в optuna, результаты для каждой комбинации гиперпараметров могли сильно разниться. Более того, наименьшая ошибка была намного больше (от 30 и вплоть 200) аналогичных испытаний на полноценном обучении ввиду маленького объема обучаемых и тестируемых данных. Следовательно, общим число экспериментов компенсировало этот недостаток. После осуществлялось тестирование уже на полных выборках в рамках второй части кода - данные нормировались, строилась константная структура на основе лучших данных из первой части, обновлялись значения гиперпараметров и запускалось обучение. \n",
    "\n",
    "Стоит отметить, что ограниченные вычислительные возможности техники не позволяли провести вычисления в optuna на большом количестве батчей или для значительного числа комбинаций гиперпараметров. Вследствие этого полученные данные постоянно модифицировались на незначительные проценты с целью достижения более оптимального эффекта. \n",
    "Если говорить о всех проведенных экспериментах, то так как они не проводились руками благодаря optuna, можно отметить невошедшие в итоговый вид программы значения гиперпараметров:\n",
    "1. Tanh, SortPlus, отсутсвие функции активации\n",
    "2. [0.0001, 0.1]\n",
    "3. [1, 6]\n",
    "4. [4, 200]\n",
    "5. dropout(p) для каждого слоя / одного слоя / двух слоев $p \\in [0.001, 0.3]$\n",
    "6. Adam, Adagrad, SGD, RMSprop\n",
    "\n",
    "Так как не имеется классических примеров экспериментов, можем отметить наиболее яркие тренды:\n",
    "\n",
    "1. Adagrad поднимал значительно изначальные значения ошибки на обучении.\n",
    "2. Dropout давал одни из лучших результатов на тесте в определенный момент. При этом встречались неожиданные выбросы, когда много нейронов одновременно выпадало.\n",
    "3. Нейронной сети не было особой разницы на количество слоев при их количестве большем или равном трем.\n",
    "4. Чрезмерно большой lr уводил градиентный спуск от возможных минимумов, перепрыгивая все и вся.\n",
    "5. Без нормировки таргета значение ошибки на тесте не опускалось ниже 8.8 ни разу.\n",
    "\n",
    "\n",
    "Пример архитектуры модели для эксперимента на 6 баллов с lr = 0.01 и без нормировки таргета:\n",
    "\n",
    "Обучающая ошибка была в районе 8.76, тестовая - 8.87"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nself.sequential = nn.Sequential(\\n        nn.Linear(in_features, 93),\\n        nn.BatchNorm1d(num_features=93),\\n        nn.ReLU6(),\\n        nn.Linear(93, 96),\\n        nn.BatchNorm1d(num_features=96),\\n        nn.ReLU(),\\n        nn.Linear(96, 94),\\n        nn.BatchNorm1d(num_features=94),\\n        nn.Sigmoid(),\\n        nn.Linear(94, 67),\\n        nn.BatchNorm1d(num_features=67),\\n        nn.Sigmoid(),\\n        nn.Linear(67, 113),\\n        nn.BatchNorm1d(num_features=113),\\n        nn.Sigmoid(),\\n        nn.Linear(113, self.out_features),\\n    )\\n'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "self.sequential = nn.Sequential(\n",
    "        nn.Linear(in_features, 93),\n",
    "        nn.BatchNorm1d(num_features=93),\n",
    "        nn.ReLU6(),\n",
    "        nn.Linear(93, 96),\n",
    "        nn.BatchNorm1d(num_features=96),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(96, 94),\n",
    "        nn.BatchNorm1d(num_features=94),\n",
    "        nn.Sigmoid(),\n",
    "        nn.Linear(94, 67),\n",
    "        nn.BatchNorm1d(num_features=67),\n",
    "        nn.Sigmoid(),\n",
    "        nn.Linear(67, 113),\n",
    "        nn.BatchNorm1d(num_features=113),\n",
    "        nn.Sigmoid(),\n",
    "        nn.Linear(113, self.out_features),\n",
    "    )\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4sAAAJICAYAAADIGHHNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deZRtZ10n/O8PIzIIAeTeAA0YQELoptXWNDITBkMghEw3LBCQRCFAImESRUEZFF8QGQyGCCpEhiZAQhLIQKIQREDkDd28rH4FwhREA0kgNCLz8PQf+5RU6rmn7jl1b53h1uezVq2dOs8++3zrqZOq+609VWstAAAAsNp15h0AAACAxaMsAgAA0FEWAQAA6CiLAAAAdJRFAAAAOsoiAAAAnX3mHWCebn7zm7f9999/3jEAAADm4iMf+ciXW2vbdja2pcvi/vvvn0svvXTeMQAAAOaiqj4/bsxhqAAAAHSURQAAADrKIgAAAB1lEQAAgI6yCAAAQEdZBAAAoKMsAgAA0FEWAQAA6CiLAAAAdJRFAAAAOsoiAAAAHWURAACAjrIIAABAR1kEAACgoywCAADQURYBAADoKIsAAAB0lEUAAAA6yiIAAAAdZREAAICOsggAAEBHWQQAAKCjLAIAANDZZ94B5u3q0944dmzbkx49wyQAAACLw55FAAAAOsoiAAAAHWURAACAjrIIAABAR1kEAACgoywCAADQURYBAADoKIsAAAB0lEUAAAA6yiIAAAAdZREAAICOsggAAEBHWQQAAKCjLAIAANBRFgEAAOgoiwAAAHSURQAAADrKIgAAAB1lEQAAgI6yCAAAQEdZBAAAoKMsAgAA0FEWAQAA6My0LFbVravqtVV1RVV9p6our6pXVNVNJ3z+DavqUVX1P6rqE1X1jar6elVdWlXPqKrrbvbXAAAAsBXsM6sXqqo7JPlgku1Jzk3yiSR3TfKUJIdW1T1ba1/ZxWbuneSNSa5JckmSc5LcLMnhSf4kydFV9YDW2rc356sAAADYGmZWFpO8KkNRPLm19sqVB6vqZUmeluSFSZ64i218Kcmjk7yttfbdVdu4UZL3JrlHkpOSvHSPJgcAANhiZnIYalXdPskhSS5Pcuqa4ecm+UaSx1TVDdfbTmvto621N60uiqPHv54fFcSD90RmAACArWxW5yzef7S8uLX2w9UDo6L3gSQ3SHK33XiN742W39+NbQAAAJDZlcU7jZaXjRn/1Gh5wG68xq+Nlu/ajW0AAACQ2ZXFfUfLr40ZX3n8JhvZeFX9RpJDk3w0yWt3se4Jo6unXnr11Vdv5OUAAAD2eotyn8UaLdvUT6w6OskrMlz85pjW2vfWW7+19prW2kGttYO2bds2fVIAAIAtYFZlcWXP4b5jxm+8Zr2JVNWRSc5IclWSg1trn91YPAAAAFabVVn85Gg57pzEO46W485p7FTVsUneluTKJPdtrX1yF08BAABgQrMqi5eMlodU1bVec3SPxHsm+VaSD02ysar6lSRvTnJFhqL4qV08BQAAgCnMpCy21j6T5OIk+yc5ac3w85PcMMnrW2vfWHmwqg6sqgPXbquqHpvkDUn+Ocl9HHoKAACw5+0zw9c6MckHk5xSVQ9I8vEkv5TkfhkOP332mvU/PlquXPwmVXW/DFc7vU6GvZXHV9Wap+X/tNZescfTAwAAbCEzK4uttc9U1UFJXpDhNhcPSfLFJKckeX5r7ZoJNvPT+dHe0F8bs87nM1wdFQAAgA2a5Z7FtNa+kOT4Cdftdhm21k5PcvqeTQUAAMBai3KfRQAAABaIsggAAEBHWQQAAKCjLAIAANBRFgEAAOgoiwAAAHSURQAAADrKIgAAAB1lEQAAgI6yCAAAQEdZBAAAoKMsAgAA0FEWAQAA6CiLAAAAdJRFAAAAOsoiAAAAHWURAACAjrIIAABAR1kEAACgoywCAADQURYBAADoKIsAAAB0lEUAAAA6yiIAAAAdZREAAICOsggAAEBHWQQAAKCjLAIAANBRFgEAAOgoiwAAAHSURQAAADrKIgAAAB1lEQAAgI6yCAAAQEdZBAAAoKMsAgAA0FEWAQAA6CiLAAAAdJRFAAAAOsoiAAAAHWURAACAjrIIAABAR1kEAACgoywCAADQURYBAADoKIsAAAB0lEUAAAA6yiIAAAAdZREAAICOsggAAEBHWQQAAKCjLAIAANBRFgEAAOgoiwAAAHSURQAAADrKIgAAAB1lEQAAgI6yCAAAQEdZBAAAoKMsAgAA0FEWAQAA6CiLAAAAdJRFAAAAOsoiAAAAHWURAACAjrIIAABAR1kEAACgoywCAADQURYBAADoKIsAAAB0lEUAAAA6yiIAAAAdZREAAICOsggAAEBHWQQAAKCjLAIAANBRFgEAAOgoiwAAAHSURQAAADrKIgAAAB1lEQAAgI6yCAAAQEdZBAAAoKMsAgAA0FEWAQAA6CiLAAAAdJRFAAAAOsoiAAAAHWURAACAjrIIAABAR1kEAACgoywCAADQURYBAADoKIsAAAB0lEUAAAA6yiIAAAAdZREAAICOsggAAEBnn3kHYHNdcerTx47d6qSXzTAJAACwTOxZBAAAoKMsAgAA0FEWAQAA6CiLAAAAdJRFAAAAOjMti1V166p6bVVdUVXfqarLq+oVVXXTKbbxy1X10qp6d1VdU1Wtqt6/mbkBAAC2mpndOqOq7pDkg0m2Jzk3ySeS3DXJU5IcWlX3bK19ZYJNnZTkiCTfTvLpJBMXTQAAACYzyz2Lr8pQFE9urR3ZWntWa+3+SV6e5E5JXjjhdl6c5C5JfjLJ4ZuSFAAAYIubSVmsqtsnOSTJ5UlOXTP83CTfSPKYqrrhrrbVWvuH1tr/31r7wR4PCgAAQJLZ7Vm8/2h5cWvth6sHWmtfT/KBJDdIcrcZ5QEAAGAdsyqLdxotLxsz/qnR8oAZZAEAAGAXZlUW9x0tvzZmfOXxm8wgCwAAALuwKPdZrNGybfoLVZ1QVZdW1aVXX331Zr8cAADAUppVWVzZc7jvmPEbr1lv07TWXtNaO6i1dtC2bds2++UAAACW0qzK4idHy3HnJN5xtBx3TiMAAAAzNKuyeMloeUhVXes1q+pGSe6Z5FtJPjSjPAAAAKxjJmWxtfaZJBcn2T/JSWuGn5/khkle31r7xsqDVXVgVR04i3wAAABc2z4zfK0Tk3wwySlV9YAkH0/yS0nul+Hw02evWf/jo2WtfrCq7pXkcaNPf3K0vGNVnb6yTmvtuD0ZHADm7aFnnjF27Lwdj5hhEgC2ipmVxdbaZ6rqoCQvSHJokock+WKSU5I8v7V2zYSb+pkkj13z2PY1jx23e2kBAAC2tlnuWUxr7QtJjp9w3Rrz+OlJTt9zqQAAAFhrUe6zCAAAwAJRFgEAAOgoiwAAAHSURQAAADrKIgAAAB1lEQAAgI6yCAAAQGem91kE9qwzTn/QuuOPOO6iGSUBAGBvY88iAAAAHWURAACAjrIIAABAxzmLAACwyf7XX1617vh/e9z2GSWBydmzCAAAQEdZBAAAoOMwVAAAlsZ5b/3y2LGHPvzmM0yyOf73q68cO3aXJ+w3wyRgzyIAAAA7oSwCAADQcRgqe72//4vDxo7d+/HnzzAJAAAsD3sWAQAA6CiLAAAAdJRFAAAAOsoiAAAAHWURAACAjquhArApHnL2i8eOXXDUb88wCYvuyDP/dt3xc3Y8cEZJAFhNWQQYedbbDl13/EXHvmtGSQAA5s9hqAAAAHSURQAAADoOQwVgbg57+8vWHT//6KfPKAkAsJY9iwAAAHSURQAAADrKIgAAAB1lEQAAgI6yCAAAQEdZBAAAoOPWGcBcnPKmB40dO/lRF80wCQAAO2PPIgAAAB1lEQAAgI6yCAAAQEdZBAAAoKMsAgAA0FEWAQAA6Lh1BgAAwDquPOW9Y8f2O/ngmeWYNXsWAQAA6CiLAAAAdJRFAAAAOsoiAAAAHWURAACAjrIIAABAR1kEAACgoywCAADQURYBAADoKIsAAAB09pl3AGAxvO6vDxk7dvxjL55hEgAAFoE9iwAAAHSURQAAADoOQwUAYMu55E1Xrzt+v0dtm1ESWFzKIjCxv3j9g9Ydf/yvXjSjJAAAbDaHoQIAANBRFgEAAOgoiwAAAHScswiwF3jwuSeNHbvwiFNnmAQA2FvYswgAAEBHWQQAAKCjLAIAANBRFgEAAOgoiwAAAHSURQAAADrKIgAAAB1lEQAAgI6yCAAAQEdZBAAAoKMsAgAA0Nln3gHYe3zi1CPWHT/wpHNnlGRzXPRXD1l3/EG/fsGMkgAAwOazZxEAAICOPYsAAMBu+dKffHrd8Vv85s/MKAl7krLIzH3stIeNHfvZJ71jhkk2x/l/9eCxY4f9+oUzTAIAABvnMFQAAAA6yiIAAAAdh6ECAMASuezUK8eOHXDSfjNMwt5OWQSYk4eee+jYsfOOeNcMkwDA1nXlKe8fO7bfyfeaYZLFoywCABvysDPPGzv2jh0PnWESADaDcxYBAADo2LMIAAAwI1f92fhTTbb/xvhTVObBnkUAAAA69iyytP7hNeufD3P3E8afSwMAAKxPWYQ5OPe1Dx47dsSvXTjDJAAAsHPK4gSuPu11Y8e2Pen4GSYBAACYDecsAgAA0FEWAQAA6DgMdQFdedqLx47t96TfnmESAABgq1IWAaZw8lnr3//olGPG3zsJAGCZOAwVAACAjrIIAABAR1kEAACgoywCAADQcYEbALaMw8569dix8495wgyTALDZrvzTf1x3fL+n/NKMkiwvZREANuChZ71u7Nh5xxw/rHPm68evs+NX93gmgBWXv+JL647v/9RbzCgJy8xhqAAAAHTsWQQA9hpHnfX+sWNnH3OvGSYBWH72LAIAANBRFgEAAOg4DBXYEp731geNH3v4RTNMAgCwHJRFAACAJXPVqWevO779pKN2+zWURQBgSzn6rA+tO/72Y+42oyQAi805iwAAAHRmWhar6tZV9dqquqKqvlNVl1fVK6rqplNu52aj510+2s4Vo+3eerOyAwAAbCUzOwy1qu6Q5INJtic5N8knktw1yVOSHFpV92ytfWWC7fzUaDsHJHlPkjOSHJjk+CSHVdXdW2uf3ZyvAgAAYGuY5Z7FV2Uoiie31o5srT2rtXb/JC9PcqckL5xwO3+UoSi+vLX2gNF2jsxQOrePXgcAAIDdMJOyWFW3T3JIksuTnLpm+LlJvpHkMVV1w11s54ZJHjNa/7lrhv9stP0HjV4PAACADZrVYaj3Hy0vbq39cPVAa+3rVfWBDGXybknevc527p7k+qPtfH3Ndn5YVRcnOSHJ/ZI4FBUAAPZCV77iI2PH9nvqL84wyd5tVoeh3mm0vGzM+KdGywNmtB0AAADWMas9i/uOll8bM77y+E1mtB0AAHbh1LOvHDt20lH7zTAJMA/VWtv8F6l6TZLHJ3l8a+0vdzL+R0l+J8nvtNZetM52fjfDhXBe2Fp7zk7GT0jy6iSvbq09ccw2TshwqGpue9vb/uLnP//5DXxFvav//NXrjm974hOSJFf9+Slj19n+xJMnfr0vvWrtKZvXdosTnz/xtr7wyuPGjt3myacnST73yiPX3cbtnnzOxK83iY/8+eFjx37xie/co6+VJO/5y8PGjt3/cefv8debxJmvO3Td8R3Hv2vibb3h9AeNHXvMcRdNvJ1JnfbG8a/3pEdP/novffP47STJMx45bOv/OWP8er/ziD3/9U3i+LPHf/9ed9Tk37sHn/uYdccvPOINE2/rIec8c+zYBUe+ZLTO7627jQuO/INhvbP/cPw6R3U/nnfLYW8f/3MzSc4/+uTReuOvb3b+0Sfu0Ux70kPPfNO64+fteNQU23rbOts5Nkly+JlvX3cb79xxdB525rnrrvOOHUdMnOmIM8e/38/dsf7PubWOOuuSsWNnH3O/qbY1iR1njT/M7cxjhsPcjj3rY2PXedsxP5skefhZn1z3dd56zJ3yiLdfvu46Zxy9f5Lk5LO/MHadU466TZLk98++Yuw6LzjqVkmSPz77i+u+3m8ddct1x1d77duvGjv2a0dvT5K8+ayr193GI4/ZliR5+5lfHrvO0TtuPnGmi988fjtJcsgjJ9/WB14/Pvs9f3XI/eHXjZ+Dux6/feLXmocrXjL+vXCrZw7vgy++5J/HrnPLZ9524tf60ks/vu74LZ5x5yTJlS8f///Vfk/72Ylfb9aueuXfrju+/ckPnHxbp47/9+72k8b/O7nbzqveun6mEx+eqvpIa+2gnY3P6jDUlT1++44Zv/Ga9TZtO62117TWDmqtHbRt27ZdvBwAAMDWNKuyuPIntXHnEt5xtBx3LuKe3g4AAADrmFVZXDlu5JCqutZrVtWNktwzybeSfGgX2/nQaL17jp63ejvXyXBF1dWvBwAAwAbM5AI3rbXPjG5rcUiSk5K8ctXw85PcMMN5ht9YebCqDhw99xOrtvPvVfWGDOccPi/JM1Zt5zeS7J/kotbawt42Y5rzEgEAAOZlVldDTZITk3wwySlV9YAkH0/ySxnuiXhZkmevWX/lDNha8/jvJjk4ydOr6ueTfDjJnZMckeSqDGUUlt40F7ABAIA9bWZlcbR38aAkL0hyaJKHJPliklOSPL+1ds2E2/lKVd09yXOTHJnk3km+kuR1SX6/tfYvm5EfAGCtlSueAru2crVTlscs9yymtfaFJMdPuO7aPYqrx65J8pTRBwAAbIqV22PAVjTTsgiLal73UgQAgEU1q6uhAgAAsESURQAAADrKIgAAAB1lEQAAgI6yCAAAQEdZBAAAoKMsAgAA0FEWAQAA6Owz7wAAAMB83OqZt5x3BBaYPYsAAAB0lEUAAAA6yiIAAAAd5ywCC+sZj7xo3hEAALYsexYBAADoKIsAAAB0lEUAAAA6yiIAAAAdZREAAICOq6ECS+93HuGqqQAAe5o9iwAAAHTsWWQit3vyOfOOAABb3ilH3WbeEYAtxJ5FAAAAOsoiAAAAHWURAACAjrIIAABAR1kEAACgoywCAADQURYBAADoKIsAAAB09pl3AABgdt654+h5RwBgSdizCAAAQEdZBAAAoKMsAgAA0HHOIrnNk0+fdwQAAGDB2LMIAABAR1kEAACg4zBUAACABbL9pMPnHSGJsggAwG74taO3zzsCsEkchgoAAEDHnkUAAGBh7Pe0n513BEaURQCmdsFRz5l3BABgkzkMFQAAgI6yCAAAQMdhqABbxAVHvmTeEYAZeMFRt5p3BGAvYc8iAAAAHWURAACAjrIIAABAxzmLALCXOG/HsfOOAMBeRFkEAJbC2cfcb94RALYUh6ECAADQURYBAADoKIsAAAB0lEUAAAA6yiIAAAAdV0MFADbNuTsOnXcEADZIWQQAANhN25/8wHlH2OOURQAANtUjj9k27wjABjhnEQAAgI49iwAAAHuh7Sc+fLeeryzCFvCY4y6adwQAAJaMsgjscU96tHIKALDsnLMIAABAR1kEAACgoywCAADQcc4iAHuF848+cd4RAGCvYs8iAAAAHXsWAYBreceOI+YdAYAFYM8iAAAAHWURAACAjrIIAABAR1kEAACg4wI3AABzdsbR+887AkBHWQQAgN1w1+O3zzsCbAqHoQIAANBRFgEAAOgoiwAAAHSURQAAADrKIgAAAB1lEQAAgI5bZwBsgtcd9a55RwAA2C32LAIAANBRFgEAAOgoiwAAAHSURQAAADrKIgAAAB1lEQAAgI6yCAAAQEdZBAAAoKMsAgAA0FEWAQAA6CiLAAAAdJRFAAAAOsoiAAAAHWURAACAjrIIAABAZ595BwAAABbXLZ9523lHYE7sWQQAAKCjLAIAANBRFgEAAOgoiwAAAHRc4AZggV14xBvmHQEA2KLsWQQAAKBjzyIAwCZ66zF3mncEgA2xZxEAAIDOzMpiVd2jqi6oqmuq6ptV9bGqempV/diU2/n1qnp1Vf3jaDutqv5ws3IDAABsRTM5DLWqjkhyVpJvJ3lLkmuSHJ7k5UnumeTYKTb30iT7JvlqkiuS3GGPhgUAAGDz9yxW1Y2T/EWSHyQ5uLX26621Zyb5+ST/kGRHVT1iik0+Isn+rbWbJbFHEQAAYBPMYs/ijiTbkry+tXbpyoOttW9X1XOSvDvJk5KcMcnGWmvv2pSULJRffOI75x0BgC3uzGN+cd4RAOZqFucs3n+03FnJe1+Sbya5R1X9xAyyAAAAMIFZlMWV60Vftnagtfb9JJ/LsIfz9jPIAgAAwARmcRjqvqPl18aMrzx+kxlkSVWdkOSEJLntbW87i5cEAGCGDnnkzecdAfYKE+1ZrKrLR7eomPTjjVNkqNGyTR9/eq2117TWDmqtHbRt27ZZvCQAAMDSmXTP4mcy3PZiUles+u+VPYf77mzFJDdesx4Ac3LBkX8w7whbznk7HjXvCACwUxOVxdbaA3bjNT6Z5KAkByT5yOqBqtonye2SfD/JZ3fjNQAAANiDZnHO4nuSPCrJoUnevGbsPklukOR9rbXvzCALAAAL6ugdzjWERTKLq6GemeTLSR5RVQetPFhV10vyh6NPT1v9hKq6QVUdWFWuQAMAADAHm75nsbX2b1X1+Ayl8b1VdUaSa5I8LMNtNc5M8pY1T7trkkuS/F2Sg1cPVNXjktxr9OnPjJaHV9WtR//9idbai/b01wEAALCVzOIw1LTWzqmq+yZ5dpJjklwvyaeTPD3JKa21aa6Eeq8kj13z2M+OPpKhYCqLAAAAu2EmZTFJWmsfSPKQCdd9b350S421Y8clOW5P5QIAAKA3i3MWAQAAWDLKIgAAAB1lEQAAgI6yCAAAQEdZBAAAoKMsAgAA0FEWAQAA6CiLAAAAdJRFAAAAOsoiAAAAHWURAACAjrIIAABAR1kEAACgoywCAADQURYBAADoKIsAAAB0lEUAAAA6yiIAAAAdZREAAICOsggAAEBnn3kHAID1nH/0yfOOAABbkj2LAAAAdJRFAAAAOg5DBQDYYn7rqFvOOwKwBOxZBAAAoKMsAgAA0FEWAQAA6CiLAAAAdJRFAAAAOsoiAAAAHWURAACAjrIIAABAR1kEAACgoywCAADQURYBAADoKIsAAAB0lEUAAAA6yiIAAAAdZREAAIDOPvMOsLfY9sQnzDsCAADAHmPPIgAAAB1lEQAAgI6yCAAAQEdZBAAAoKMsAgAA0FEWAQAA6CiLAAAAdJRFAAAAOsoiAAAAHWURAACAjrIIAABAR1kEAACgoywCAADQURYBAADoKIsAAAB0lEUAAAA6yiIAAAAdZREAAICOsggAAEBHWQQAAKCjLAIAANBRFgEAAOgoiwAAAHSURQAAADrKIgAAAB1lEQAAgI6yCAAAQEdZBAAAoKMsAgAA0FEWAQAA6CiLAAAAdJRFAAAAOsoiAAAAHWURAACAjrIIAABAR1kEAACgoywCAADQURYBAADoKIsAAAB0lEUAAAA6yiIAAAAdZREAAICOsggAAEBHWQQAAKCjLAIAANBRFgEAAOgoiwAAAHSURQAAADrKIgAAAB1lEQAAgI6yCAAAQEdZBAAAoKMsAgAA0FEWAQAA6CiLAAAAdJRFAAAAOvvMOwAbc4sTnz/vCAAAwF7MnkUAAAA6yiIAAAAdZREAAICOsggAAEBHWQQAAKCjLAIAANBRFgEAAOgoiwAAAHRmVhar6h5VdUFVXVNV36yqj1XVU6vqx6bYxn+qqidX1YVVdXlVfaeqvlJVf1NVR29mfgAAgK1kJmWxqo5I8r4k90lydpJTk1w3ycuTnDHFpp6c5JQkd0pySZKXJbkoyb2TnFVVL9uDsQEAALasfTb7Barqxkn+IskPkhzcWrt09PjvJXlPkh1V9YjW2iSl8cOjbfzdmte4c5IPJXlaVb2ptfaRPfpFAAAAbDGz2LO4I8m2JGesFMUkaa19O8lzRp8+aZINtdbevrYojh7/eJK3jD49eLfSAgAAMJOyeP/R8l07GXtfkm8muUdV/cRuvs73Rsvv7+Z2AAAAtrxZlMU7jZaXrR1orX0/yecyHA57+42+wOhQ12OStCQXb3Q7AAAADGZRFvcdLb82Znzl8ZtsZONVVUn+Msl+SU4bHZK63vonVNWlVXXp1VdfvZGXBAAA2OtNVBZHt6loU3y8cYoMNVq26eMnSV6a5Ngkf5/k6btaubX2mtbaQa21g7Zt27bBlwQAANi7TXo11M8k+fYU271i1X+v7Dncd2crJrnxmvUmVlUvSfK0DOc+HtZa+8602wAAAKA3UVlsrT1gN17jk0kOSnJAkmvd0qKq9klyuwwXpfnsNButqpcneWqG+y0+tLX2zd3ICAAAwCqzOGfxPaPloTsZu0+SGyT54KR7BWtwaoai+DcZ9igqigAAAHvQLMrimUm+nOQRVXXQyoNVdb0kfzj69LTVT6iqG1TVgVV12zWPV5LXJDkxyYVJHtZa+9ZmhgcAANiKJj1nccNaa/9WVY/PUBrfW1VnJLkmycMy3FbjzCRvWfO0u2Y4vPTvkhy86vHfT/K4JN9K8tEkzxr647V8tLV2zh7+MgAAALaUTS+LSdJaO6eq7pvk2Rnuh3i9JJ/OcPXSU1prk14J9Xaj5fWT/M6Ydf46ibIIAACwG2ZSFpOktfaBJA+ZcN335ke31Fj9+HFJjtuTuQAAAOjN4pxFAAAAlkxNfgTo3qeqrk7y+Q089eYZLtqzbJY1d7K82Zc1d7K82Zc1d7K82Zc1d7K82Zc1d7K82Zc1d7K82Zc1d7K82Zc1d7K82Rch90+31rbtbGBLl8WNqqpLW2sH7XrNxbKsuZPlzb6suZPlzb6suZPlzb6suZPlzb6suZPlzb6suZPlzb6suZPlzb6suZPlzb7ouR2GCgAAQEdZBAAAoKMsbsxr5h1gg5Y1d7K82Zc1d7K82Zc1d7K82Zc1d7K82Zc1d7K82Zc1d7K82Zc1d7K82Zc1d7K82Rc6t3MWAQAA6NizCAAAQEdZBAAAoKMsTqCqdlTVK6vq76vq36qqVdUb551rUlV176o6q6q+WFXfGS0vrqqHzDnXxPNaVT9eVU+pqtdV1Uer6ruj9R8369yjPFO/J2rw2Kp6b1VdU1XfqqpB884AAA0YSURBVKrPVdVbq+qAGeX+qap6XFWdXVWfHmX4WlW9v6p+vaqus2b9hZj3aXOvet7c53yU48VV9e6q+sIowzVV9b+q6rlV9VNr1l2IOZ8296rnLMSc7yTXY0bz2M1lVd2kqp5ZVW+qqn+qqu+P1nvgvPKutl72Vev8eFWdXFX/OPp/4xtVdVlVvb6qdnrvrE3IefmqnGs/vrSTvIvyPp8496rnLMz7vCb4Hb9I8z1t9lXrzn3Oq+q4dd4rKx8/WLX+Qsz7tLlXPW/ucz7KcdjoffEvowyfraq3VdXd16y3EPO9keyr1l+IOV9tn3m86BJ6TpKfS/LvSf4lyYHzjTO5qnpOkj/IcLPP85J8McPNP/9bkoOTXDC3cNPN6w2TvGL031cm+VKS22xquvVN9Z6oqusleVuShyb5ZJL/keTrSW6V5N5JDkhy2SbmXXFsktMyvA8uSfLPSfZLcnSSv0zy4Ko6tv3oZOZFmfdpcy/SnCfJ05L8zyR/k+SqDPN6tyTPS3JCVd2ttfaF0bqLMufJdLkXbc7/Q1XdJskrM/z/+pM7WWX/JH88+u9/yfDzcr+ZhNuFCbKnqm6W5MIkd83w/Xptku9meN88MMPXcvUs8ib5Wn70/l3t39d8vkjv82Ty3Av1Pp/id/yizfdU/z5ZoDn/aJLnjxm7d5L7Z/h/ccWizPu0uRdmzqvqxUl+K8lXkpyT4f3yM0mOSHJMVf1qa23lj/WLMt9Jps6+MHPeaa352MVHkvsluWOSyvADrCV547xzTZD72FHWv0lyo52M//iyzGuS6yZ5cJJbjj5/3mj9xy169tH6p47W+aMk15nX9yLDL4TD12ZIcosMBawlOWbR5n3a3Is056PXut6Yx184yviqRZvzaXMv2pyves1K8rdJPpPkJTubyyQ3TfKAJDcbfX76aL0HzjrvtNlH6503GnvSmG382IzyXp7k8gnXXaT3+cS5R+svxPs8U/yOX6T5njb7Is35Lr6mfxhlfNiizvukuRdlzjP8jv9BhtK3fc3Y/Ub5PruI8z1t9kWZ8519OAx1Aq21S1prn2qj79QyqOGwvBcn+WaSX2mtfX3tOq2178082LVff+J5ba19t7V2YWvti7PItivTZK+qOyR5YpL/N8mzW2s/3Mn2ZvK9aK29p7X2zrUZWmtfSvLno08PXvX4Qsz7tLkXac5Hr/XtMUNvHS3vuGrdhZjzUZaJcy/anK9ycoY/Nhyf5Bs7W6G19tXW2rtba9fMNNmu7TJ7Vd0/yWFJzmytnbZ2vA26w8vmbZHe59NYlPf5tL/jF2m+p82+KHO+nqq6S4ajLv41yfkrjy/SvO/MuNwLNOc/neGUuX9srV215vUvybDXbduqxxZpvqfKvkBz3nEY6t7rHklul+TMJF+tqsOS3CXJt5N8uLX2D/MMt8U8MsMPjL9OcuOqOjzDYRFfSfKe1tqn5xlulZUfQt+fa4rp7Sz3ssz54aPlx+aaYno7y71wc15Vd07yoiR/2lp736hYLYUpsv/KaHl6Ve2X4fCl7Rn+mn1xa+1fNz/ttfxEVT06yW0zFNyPJXnfIhbWNSbNvSjv82X+HT9t9kWZ8/U8YbT8qyV4r682LveizPmnMhxSf9equnlr7csrA1V1nyQ3ynB45yKaNvuizHlHWdx7/ffR8soM57D819WDVfW+JDtaa7M6j2UrW/le7JvhcLLVFwZpVXVakpPn+QumqvZJ8qujT981rxzTWif3Qs55Vf1mhvPO9k1yUJJ7ZfhH6YtmmWNaE+ZeqDkfvTfekOEw5d+dxWvuKVNmX5n3AzLs8b3BqrHvVdULWmt/uOdTjnWLDNlX+1xVHd9a+7sZ5pjWpLkX5X2+zL/jp82+KHO+U1V1/SSPTvLDDOfQL4Vd5F6IOW+tXVNVv53kZUn+qarOyVCe7pDkYRkOY37COpuYmw1kX4g53xmHoe69to+WT0xy/QwXObhRhr/eXZTkPhlOomXzrXwvXpDk0gy/GG+U4RypzyQ5McnvzSfaf3hRhvfGBa21i+acZRrjci/qnP9mkucmeWqGwvWuJIcs6D/oVpsk96LN+e9nuFDGca21b83wdfeEabKvzPtLkpyV4dDgm2S4+NNXk/xBVR23STnXel2G7/ctMlxo4r8meXWGCwhdWFU/N6Mc05om96K8z5f5d/y02Rdlzsd5eIb/5y5sqy74tQTWy70wc95ae0WGn2f7JHl8kmdlOOf1C0lOX3uI5yKZMvvCzHmnzeFEyWX+yJJc4CbDlf1ahpNrf27N2PUzvFFbkrvPO+tG5jULdJL4rrIn+fBo/AtJrr9m7OdG36N/S3LdOeU/eZTv4xld4GNJ5n1s7iWY8/2SHJXhamdXJPmFJZnzsbkXac4zXBX0+0n+eCNzmTle4Gba7BmuUtsynOdSa8YOH419cs7vmz8Z5Th7nXUW5n2+Xu5FeZ9nN3/Hz3O+p82+KHO+ztfzgVG+wydYd2He5+vlXqQ5z3A10e9n2EN3+wxHT/xChj8stLU/KxdpvqfJvkhzvvbDnsW911dHy8+21v6/1QNt+Ev1yl6Yu8401da08r14V1uzl2D0vflchr8e3XnWwarqpCR/muSfktyvLd4FPnZqgtwLO+ejDFe21s5OckiGQ01eP48c09pF7oWY81WHcF6W+e+xn8oGs6/M+zlt9K+KVc7PcM7MAVW1755JuSErF6G6zxwzbMTOci/E+zzL/Tt+2uyLMuedqvrPGc7B/JfM91ZkU5kg90LMeVUdnOFiSO9orT29tfbZ1to3W2v/M8MfLv81yTOq6vabmWMjNpB9IeZ8Z5TFvdcnR8v/M2Z85U15/Rlk2eoW8ntRVU9N8mdJ/neGwrXTm08vmglzL+Scr9Va+3yGwvtfqurm88wyjTG5F2XOfzLD+Xt3TvLtWnXT6QyH0ibJX4we29l99eZpI9nHznsbrqb3b6NP5/leXznU6oZzzLARO8u9KO/zRcmxEdNmX+SvdW+7sM2KRZnzh46Wl6wdaK19M8PeuOtkOGx/0UybfVHmvOMCN3uv92XY9X3Hqrpua+27a8bvMlpePtNUW9O7kzw5P5rz/1BVP5Ef3X7g8lkFGp10/aIMN+r95bbqKl2LbIrcCzfn67jVaLlM/9BI+tyLMuffSfJXY8Z+IcMv5vdn+MW8aFeM3Ej2d2c43HRn875fhpucfyPDzaDn5e6j5WfnmGEjdpZ7Ud7ny/w7ftrsizLna1/7ekkek+ECMeP+v104E+ZelDn/idFy25jxlcfXvocWwbTZF2XOO/Ys7qVG/4h+S4arKv3+6rGq+uUkD0rytSzRlS+X2IUZ/rHxoNHcr/Z7Gb5HfzerPXtV9XsZCtdHkjxgiYriNLkXZs6r6sCqusVOHr9OVb0ww0ntH2ytfbV/9vxsIPdCzHlr7Vuttcft7CPJO0ar/fXosbdsZpZpbTD7mzL8Jfq4qvqPq0qO7mX3x6NPz2ytbeotcarqv1TVzXby+E9nOBIgSd64mRk2YgO5F+V9vrS/4zeQfSHmfCeOTXLTDBdYW6YL20ySe1Hm/O9HyxOq6j+tHqiqBye5Z4Zbrnxwk3NsxLTZF2XOO9Wf4sBaVXVkkiNHn94iww+yz+ZHb4Qvt9Z+cx7Z1lNV2zOcwPwzGbJ+OMNNQo/KcBLtr7TW5na1tGnntaqeleTA0ac/n+GE3w9muJdNkry/tTaTy1ZvIPu9klyc5LpJzk7y+QyXSb5PkquT3Ku1dtkMcj82w8U7fpDklRl+Ia91eWvt9FXPmfu8bzD3osz5UzNcqfJ9Ga5o9pUMF4q5b4YT3r+Uofz+06rnLMKcbyT3Qsz5OFX1vAyHcz5+7fxV1Z9k2AuXDFd8vUOGr2Xl5s7ntNbmdj+vXWQ/NskZGfZMnpVhru+bYW/kp5Pco23yFXdH+Z6V4ZCrz2W44fQdkhyW5HoZzos6avVepAV5n28k90K8z6f9Hb8I870b2Rdiztd8DX+f4WfFw1pr71xnvYWZ91GeSXPPfc5Hf/S6KMMVc78+yvGlDIfqPzRJJXlqa+1PVz1nIeZ7g9nnPuc7tasr4Pi41tWUxn1cPu+M62S/WYarMH0uw67uryQ5N8ndFiDbVPOa5L27WP/0Rc0+es5/zvDX1KtG34svZLg8+60XKHdL8t5Fm/eN5F6gOb9LklMzHDr75QyHX30tw9Urn5edXIF2QeZ86tyLMucTvI+6K+NlOLRnvTl/3qJmH43fI8l5GX7GfzdDwf+TJDedUb77Jnlzkk9k2NP5vQz/uPmbDPdCrZ08ZxHe51PnHj1vId7nmeJ3/CLM90azL9Kcj7LcOT+6cuWP7WLdhZn3aXIvypwn+fEMt236UIZzsL8/ynNehls4LfJ8T5V9UeZ87Yc9iwAAAHScswgAAEBHWQQAAKCjLAIAANBRFgEAAOgoiwAAAHSURQAAADrKIgAAAB1lEQAAgI6yCAAAQEdZBAAAoPN/AaGqL59KQ/S6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "correlations = df.loc[:, 1:].corrwith(df.loc[:, 0]).sort_values(ascending=False)\n",
    "plot = sns.barplot(x=correlations.index, y=correlations)\n",
    "plot.figure.set_size_inches(15, 10)\n",
    "plt.xticks(range(1, len(set(correlations.index)), 5), list(set(correlations.index))[::5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "intro-hw01.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
